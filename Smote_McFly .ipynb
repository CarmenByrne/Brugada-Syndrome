{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d6c947",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mcfly\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import os\n",
    "from mcfly.find_architecture import train_models_on_samples\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d26a0",
   "metadata": {},
   "source": [
    "# Read Processed File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11395ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.read_csv(\"Output/output.csv\")\n",
    "\n",
    "#check for nans in df\n",
    "processed.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3df58",
   "metadata": {},
   "source": [
    "# Split Data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed.iloc[:, 1:]\n",
    "y = processed.iloc[:,0]\n",
    "y = y.astype(int)\n",
    "\n",
    "del processed\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81048a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get one outcome var per patient: select first element every 2500 ECG time points\n",
    "y = y[np.arange(0, X.shape[0], 2500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf97071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape X into a 3D array there is an element per patient which contains 8 leads and 2500 rows\n",
    "X = X.to_numpy()\n",
    "X = X.reshape(int(X.shape[0]/2500), 2500, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train, validation and test sets\n",
    "X_train_imb, X_test, y_train_imb, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4641fa34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"train set size\", X_train_imb.shape[0])\n",
    "print(\"validation set size\", X_val.shape[0])\n",
    "print(\"test set size\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class imbalance\")\n",
    "print(y_train_imb.tolist().count(0))\n",
    "print(y_train_imb.tolist().count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27a726",
   "metadata": {},
   "source": [
    "# SMOTE on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7617324",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_imb.shape\n",
    "print(nsamples, nx, ny)\n",
    "\n",
    "X_train_imb = X_train_imb.reshape((nsamples, nx*ny))\n",
    "X_train_imb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy = \"minority\", random_state=0)\n",
    "X_train, y_train = smote.fit_resample(X_train_imb, y_train_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade09715",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class imbalance solved?\", y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a42f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put X_train in 3D again: shape X into a 3D array there is an element per patient which contains 8 leads and 2500 rows\n",
    "print(\"new size of X_train\", X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], 2500, int(X_train.shape[1]/2500))\n",
    "print(\"Restored dimensions of X_train: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae696c",
   "metadata": {},
   "source": [
    "# Put in McFly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7364d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_cols_per_label(y): \n",
    "    \n",
    "    y = y.replace({0:\"no_BRS\", 1:\"BRS\"})\n",
    "    \n",
    "    #create two columns, one per class\n",
    "    print(y.head())\n",
    "\n",
    "    #integer mapping\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(y)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "\n",
    "    #one hot encoding\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    print(integer_encoded)\n",
    "    print(\" \")\n",
    "    print(onehot_encoded)\n",
    "    print(\"-------\")\n",
    "    \n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = two_cols_per_label(y_train)\n",
    "y_test = two_cols_per_label(y_test)\n",
    "y_val = two_cols_per_label(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278e4a4",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_leads(row, df):\n",
    "\n",
    "    #fig, axis = plt.subplots(6, 2, sharex=True, sharey=True, figsize=(6, 12))\n",
    "    fig, axis = plt.subplots(4, 2, sharex=True, sharey=True, figsize=(6, 12))\n",
    "    \n",
    "    axis[0,0].plot(np.array(df[row, :, 0]))\n",
    "    axis[0,0].set_title(\"Lead I\")\n",
    "    \n",
    "    axis[0,1].plot(np.array(df[row, :, 1]))\n",
    "    axis[0,1].set_title(\"Lead II\")\n",
    "    \n",
    "    axis[1,0].plot(np.array(df[row, :, 2]))\n",
    "    axis[1,0].set_title(\"Lead V1\")\n",
    "    \n",
    "    axis[1,1].plot(np.array(df[row, :, 3]))\n",
    "    axis[1,1].set_title(\"Lead V2\")\n",
    "    \n",
    "    axis[2,0].plot(np.array(df[row, :, 4]))\n",
    "    axis[2,0].set_title(\"Lead V3\")\n",
    "    \n",
    "    axis[2,1].plot(np.array(df[row, :, 5]))\n",
    "    axis[2,1].set_title(\"Lead V4\")\n",
    "    \n",
    "    axis[3,0].plot(np.array(df[row, :, 6]))\n",
    "    axis[3,0].set_title(\"Lead V5\")\n",
    "    \n",
    "    axis[3,1].plot(np.array(df[row, :, 7]))\n",
    "    axis[3,1].set_title(\"Lead V6\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_leads(7000, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dd1b40",
   "metadata": {},
   "source": [
    "# Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c889d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "metric = \"accuracy\"\n",
    "models = mcfly.modelgen.generate_models(X_train.shape,\n",
    "                                       number_of_classes = num_classes,\n",
    "                                       number_of_models = 4, \n",
    "                                       metrics = [metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca29825",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_print = range(len(models))\n",
    "for i, item in enumerate(models):\n",
    "    if i in models_to_print:\n",
    "        model, params, model_types = item\n",
    "        print(\"-----------------------------------------------------------\")\n",
    "        print(\"Model \" + str(i))\n",
    "        print(\" \")\n",
    "        print(\"Hyperparameters: \")\n",
    "        print(params)\n",
    "        print(\" \")\n",
    "        print(\"Model description: \")\n",
    "        model.summary()\n",
    "        print(\" \")\n",
    "        print(\"Model type: \")\n",
    "        print(model_types)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e50221",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955006cf",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultpath = os.path.join(\"Mcfly_output\", \"models3\")\n",
    "if not os.path.exists(resultpath):\n",
    "    os.makedirs(resultpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc8df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputfile = os.path.join(resultpath, \"modelcomparison.json\")\n",
    "histories, val_accuracies, val_losses = train_models_on_samples(X_train, y_train,\n",
    "                                                               X_val, y_val,\n",
    "                                                               models, nr_epochs=40,\n",
    "                                                               subset_size=500,\n",
    "                                                               early_stopping_patience = 10,\n",
    "                                                               verbose = True,\n",
    "                                                               batch_size = 50,\n",
    "                                                               outputfile = outputfile)\n",
    "\n",
    "print(\"Details of the training process were stored in \", outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906081b",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"accuracy\"\n",
    "modelcomparisons = pd.DataFrame({\"model\": [str(params) for model, params, model_types in models],\n",
    "                                \"model-type\": [str(model_types) for model, params, model_types in models],\n",
    "                                \"train_{}\".format(metric): [history.history[metric][-1] for history in histories],\n",
    "                                \"train_loss\": [history.history[\"loss\"][-1] for history in histories],\n",
    "                                \"val_{}\".format(metric): [history.history[\"val_{}\".format(metric)][-1] for history in histories],\n",
    "                                \"val_loss\": [history.history[\"val_loss\"][-1] for history in histories]\n",
    "                                })\n",
    "modelcomparisons.to_csv(os.path.join(resultpath, \"modelcomparisons.csv\"))\n",
    "\n",
    "modelcomparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaff84b",
   "metadata": {},
   "source": [
    "# Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c57cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_index = np.argmax(val_accuracies)\n",
    "best_model, best_params, best_model_types = models[best_model_index]\n",
    "print(\"Model type and parameters of the best model\")\n",
    "print(best_model_types)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[best_model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7212f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new model\n",
    "_,_,_ = train_models_on_samples(X_train, y_train,\n",
    "                               X_val, y_val,\n",
    "                               [models[best_model_index]], nr_epochs = 300,\n",
    "                               subset_size = None,\n",
    "                               batch_size = 100,\n",
    "                               early_stopping_patience = 15,\n",
    "                               verbose = True,\n",
    "                               outputfile = outputfile,\n",
    "                               metric = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"my_bestmodel.h5\"\n",
    "model_path = os.path.join(resultpath, modelname)\n",
    "best_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload best model and check that weights are the same as the new one\n",
    "model_reloaded = tf.keras.models.load_model(model_path)\n",
    "np.all([np.all(x==y) for x,y in zip(best_model.get_weights(), model_reloaded.get_weights())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cee2e6",
   "metadata": {},
   "source": [
    "# Investigate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize = X_val.shape[0]\n",
    "probs = models[0][0].predict(X_val[:datasize, :, :], batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d90704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns: predictions, rows: true values\n",
    "labels = [\"BRS\", \"no_BRS\"]\n",
    "\n",
    "predicted = probs.argmax(axis=1)\n",
    "y_index = y_val.argmax(axis=1)\n",
    "confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "confusion_matrix.reindex(columns =[l for l in labels], fill_value=0)\n",
    "confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
