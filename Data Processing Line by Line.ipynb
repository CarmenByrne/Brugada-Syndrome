{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6e567e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6c72a-5b66-4e5c-bb5c-ac84cfa0426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import gc\n",
    "from scipy import signal\n",
    "import csv\n",
    "from pathlib import Path\n",
    "%matplotlib widget\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea67d6",
   "metadata": {},
   "source": [
    "# Paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clinical data \n",
    "path_clinical_data = \"20210305Ajmaline_AI.sav\"\n",
    "\n",
    "#negative BrS examples\n",
    "path_negative = \"Ajmaline_data_json/negative\"\n",
    "path_positive = \"Ajmaline_data_json/positive\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1ef5ba",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c68d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill csv file at specified directory\n",
    "#action: \"w\" to write csv file, \"a\" to append new rows\n",
    "def write_to_csv(data, file_path, action):       \n",
    "    with open(file_path, action, newline = \"\") as csv_file: \n",
    "        csv_writer = csv.writer(csv_file, delimiter = \",\")\n",
    "        for line in data:\n",
    "            csv_writer.writerow(line)\n",
    "        csv_file.close()\n",
    "    return\n",
    "\n",
    "#specify directory to save csv file of data after processing\n",
    "dir_path = Path(\"Output\")\n",
    "file_name = \"output.csv\"\n",
    "file_path = dir_path.joinpath(file_name)\n",
    "\n",
    "#make csv file and fill with column names\n",
    "header_row = [\"file_name\", \"outcome\", \"lead_I\", \"lead_II\", \"lead_III\", \"lead_aVL\", \"lead_aVR\", \n",
    "              \"lead_aVF\", \"lead_V1\", \"lead_V2\", \"lead_V3\", \"lead_V4\", \"lead_V5\", \"lead_V6\"]\n",
    "data=[header_row]\n",
    "write_to_csv(data, file_path, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c431604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#puts dates in \"clinical\" in same format as in ECG records\n",
    "#returns dictionary of patient id and test date\n",
    "def id_w_date(clinical):\n",
    "    id_date = {}\n",
    "    clinical[\"Provocation_date\"] = pd.to_datetime(clinical[\"Provocation_date\"])\n",
    "    \n",
    "    for row in np.arange(clinical.shape[0]):\n",
    "        p_id = str(int(clinical[\"ID\"][row]))\n",
    "        formatted_date = datetime.date.strftime(clinical[\"Provocation_date\"][row], \"%m-%d-%Y\")\n",
    "        id_date[p_id]  = formatted_date\n",
    "        \n",
    "    return id_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d255bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ajmaline_tested(data, ajmaline_id_date):\n",
    "    #checks if data contains patientID, if not, assume not ajmaline tested.\n",
    "    #if yes, check if patient id is in list of ajmaline tested and check date of test\n",
    "    \n",
    "    if data[\"RestingECG\"].__contains__(\"PatientDemographics\") and data[\"RestingECG\"].__contains__(\"TestDemographics\"):\n",
    "        p_demographics = data[\"RestingECG\"][\"PatientDemographics\"]\n",
    "        t_demographics = data[\"RestingECG\"][\"TestDemographics\"]\n",
    "        \n",
    "        if p_demographics.__contains__(\"PatientID\") and t_demographics.__contains__(\"AcquisitionDate\")  :            \n",
    "            patient_id = p_demographics[\"PatientID\"] \n",
    "            test_date = str(t_demographics[\"AcquisitionDate\"])\n",
    "            \n",
    "            if patient_id in ajmaline_id_date.keys() and ajmaline_id_date[patient_id] == test_date:\n",
    "                return True            \n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652876b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lead_data(data):\n",
    "    lead_I = []\n",
    "    lead_II = []\n",
    "    lead_V1 = []\n",
    "    lead_V2 = []\n",
    "    lead_V3 = []\n",
    "    lead_V4 = []\n",
    "    lead_V5 = []\n",
    "    lead_V6 = []\n",
    "    \n",
    "    lead_indx = {0: lead_I, 1: lead_II, 2: lead_V1, 3: lead_V2, 4: lead_V3,\n",
    "             5: lead_V4, 6: lead_V5, 7: lead_V6}\n",
    "    \n",
    "    #get waveform info\n",
    "    waveform = pd.DataFrame(data[\"RestingECG\"][\"Waveform\"])\n",
    "    \n",
    "    #use rhythm ECG (not median ECG)\n",
    "    rhythm_ecg = waveform[waveform[\"WaveformType\"]==\"Rhythm\"]\n",
    "    \n",
    "    #get elements inside LeadData \n",
    "    lead_data = rhythm_ecg[\"LeadData\"]\n",
    "    \n",
    "    #find ECG data per lead and add offset\n",
    "    for index in lead_indx:\n",
    "        leadoffset = float(lead_data[1][index][\"LeadOffsetFirstSample\"])\n",
    "            \n",
    "        decoded = np.array(np.frombuffer(b64decode(lead_data[1][index][\"WaveFormData\"]), dtype=np.int16)) - leadoffset\n",
    "        lead_indx[index] = decoded\n",
    "        \n",
    "    return lead_indx[0], lead_indx[1], lead_indx[2], lead_indx[3], lead_indx[4], lead_indx[5], lead_indx[6], lead_indx[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4da6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample leads measured at double speed\n",
    "#keeps values at every other index\n",
    "def downsample(lead):    \n",
    "    if len(lead) == 5000:\n",
    "        indeces = np.arange(0,5000,2)\n",
    "        downsampled = lead[indeces]\n",
    "        return downsampled\n",
    "    return lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate leads III, aVL, aVR, aVF\n",
    "def calculate_missing_leads(lead_I, lead_II):\n",
    "    lead_III = lead_II - lead_I\n",
    "    lead_aVL = (lead_I - lead_III)/2.0\n",
    "    lead_aVR = (lead_I + lead_II)/(-2.0)\n",
    "    lead_aVF = (lead_II + lead_III)/2.0    \n",
    "    return lead_III, lead_aVL, lead_aVR, lead_aVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab5944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise each row by its maximum value\n",
    "def normalize(lead):\n",
    "    max_value = max(lead)\n",
    "    if max_value == 0:\n",
    "        max_value = 0.0000000001\n",
    "    normalised = lead/max_value \n",
    "    return normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill csv file at specified directory\n",
    "#action: \"w\" to write csv file, \"a\" to append new rows\n",
    "def write_to_csv(data, file_path, action):       \n",
    "    with open(file_path, action, newline = \"\") as csv_file: \n",
    "        csv_writer = csv.writer(csv_file, delimiter = \",\")\n",
    "        for line in data:\n",
    "            csv_writer.writerow(line)\n",
    "        csv_file.close()\n",
    "    return\n",
    "\n",
    "#specify directory to save csv file of data after processing\n",
    "dir_path = Path(\"Output\")\n",
    "file_name = \"output.csv\"\n",
    "file_path = dir_path.joinpath(file_name)\n",
    "\n",
    "#make csv file and fill with column names\n",
    "header_row = [\"file_name\", \"outcome\", \"time_stamp\", \"lead_I\", \"lead_II\", \"lead_III\", \"lead_aVL\", \"lead_aVR\", \n",
    "              \"lead_aVF\", \"lead_V1\", \"lead_V2\", \"lead_V3\", \"lead_V4\", \"lead_V5\", \"lead_V6\"]\n",
    "data=[header_row]\n",
    "write_to_csv(data, file_path, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa1cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(directory, clinical, pos_or_neg):    \n",
    "    ajmaline_id_date = id_w_date(clinical)\n",
    "  \n",
    "    #iterate through all file names in the directory\n",
    "    for name in glob.glob(directory + \"/*\"):\n",
    "        #open file\n",
    "        f = open(name) \n",
    "        \n",
    "        #load file as json file\n",
    "        data = json.load(f)         \n",
    "\n",
    "        #check if patient id is in list of patients that were tested with ajmaline\n",
    "        #only keep file if not tested with ajmaline \n",
    "        if is_ajmaline_tested(data,ajmaline_id_date) is False:\n",
    "\n",
    "            #get file name without directory\n",
    "            base_name = os.path.basename(name)\n",
    "\n",
    "            #extract ecg lead data and decode, save lead per array with base_name and test outcome\n",
    "            #0: negative test, 1: positive test\n",
    "            lead_I, lead_II, lead_V1, lead_V2, lead_V3, lead_V4, lead_V5, lead_V6 = get_lead_data(data)\n",
    "                        \n",
    "            #downsample all leads with 5000 measurements to 2500 measurements   \n",
    "            lead_I = downsample(lead_I)\n",
    "            lead_II = downsample(lead_II)\n",
    "            lead_V1 = downsample(lead_V1)\n",
    "            lead_V2 = downsample(lead_V2)\n",
    "            lead_V3 = downsample(lead_V3)\n",
    "            lead_V4 = downsample(lead_V4)\n",
    "            lead_V5 = downsample(lead_V5)\n",
    "            lead_V6 = downsample(lead_V6)           \n",
    "            \n",
    "            #calculate missing leads\n",
    "            lead_III, lead_aVL, lead_aVR, lead_aVF = calculate_missing_leads(lead_I, lead_II)\n",
    "            \n",
    "            #normalise  \n",
    "            lead_I = normalize(lead_I)\n",
    "            lead_II = normalize(lead_II)\n",
    "            lead_III = normalize(lead_III)\n",
    "            lead_aVL = normalize(lead_aVL)\n",
    "            lead_aVR = normalize(lead_aVR)\n",
    "            lead_aVF = normalize(lead_aVF)            \n",
    "            lead_V1 = normalize(lead_V1)\n",
    "            lead_V2 = normalize(lead_V2)\n",
    "            lead_V3 = normalize(lead_V3)\n",
    "            lead_V4 = normalize(lead_V4)\n",
    "            lead_V5 = normalize(lead_V5)\n",
    "            lead_V6 = normalize(lead_V6)     \n",
    "            \n",
    "            #make arrays of same length as leads of file name, outcome, and time\n",
    "            name = [base_name] * len(lead_I)\n",
    "            outcome = [pos_or_neg] * len(lead_I)\n",
    "            time_stamps = np.arange(0, len(lead_I), 1)\n",
    "            prefix = \"t\"\n",
    "            time = [prefix + str(sub) for sub in time_stamps]            \n",
    "            \n",
    "            #put everything different time stamps as different rows\n",
    "            leads = np.array([name, outcome, time, lead_I, lead_II, lead_III, lead_aVL, lead_aVR, lead_aVF, lead_V1, lead_V2, lead_V3, lead_V4, lead_V5, lead_V6]).T\n",
    "            \n",
    "            #write to csv\n",
    "            write_to_csv(leads, file_path, \"a\")\n",
    "            \n",
    "    return     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b866f5f",
   "metadata": {},
   "source": [
    "# Read and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41378ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read clinical data\n",
    "clinical = pd.read_spss(path_clinical_data)\n",
    "\n",
    "#Read ECG data stored as json files\n",
    "process_data(path_negative, clinical, 0)\n",
    "process_data(path_positive, clinical, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
