{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e283d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "import glob\n",
    "from base64 import b64decode\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_key_table_path = \"BrS_negatives_translation_table.csv\"\n",
    "positive_key_table_path = \"BrS_positives_translation_table.csv\"\n",
    "path_negative = \"AnonymisedECGs_json/negative\"\n",
    "path_positive = \"AnonymisedECGs_json/positive\"\n",
    "test_dates_path = \"20210305Ajmaline_AI.sav\"\n",
    "genetic_data_path = \"GeneticData/available_BRS_PRS.txt\"\n",
    "\n",
    "split_path = \"Removed_no_genetic/Data_Final_Same_Test_Balanced_Val/split/train_val_test.json\"\n",
    "labels_path = \"Removed_no_genetic/Data_Final_Same_Test_Balanced_Val/labels/labels.npy\"\n",
    "samples_path = \"Removed_no_genetic/Data_Final_Same_Test_Balanced_Val/samples/\"\n",
    "\n",
    "\n",
    "ecg_only_split_path = \"400_dumped/Final_Data/split/train_val_test.json\"\n",
    "\n",
    "remove_no_dna = True #set to true if want to filter out patients not genetically tested\n",
    "to_val = False #set to true if want the removed samples from the training set to go to the validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a737fdb",
   "metadata": {},
   "source": [
    "# I. Read Data and Check  Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef995ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read test dates and genetic data\n",
    "test_dates = pd.read_spss(test_dates_path)\n",
    "genetic = pd.read_csv(genetic_data_path, header=0, sep=\",\")\n",
    "negative = pd.read_csv(negative_key_table_path, header=0)\n",
    "positive = pd.read_csv(positive_key_table_path, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608368af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all keys into one df\n",
    "keys = pd.concat([negative, positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys.columns = keys.columns.str.replace(\" \", \"\") #remove spaces in column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6964f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put dates in same format as in ECG files\n",
    "dates = {}\n",
    "test_dates[\"Provocation_date\"] = pd.to_datetime(test_dates[\"Provocation_date\"])\n",
    "    \n",
    "for row in np.arange(test_dates.shape[0]):\n",
    "    formatted_date = datetime.date.strftime(test_dates[\"Provocation_date\"][row], \"%m-%d-%Y\")\n",
    "    patient_id = int(test_dates[\"ID\"][row])\n",
    "    dates[patient_id] = formatted_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of patients whose genetic data is available\n",
    "genetic_tested = np.array(genetic[\"anonymous_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patients(path_to_files, ajmaline_tested, not_tested, no_dna, diff):\n",
    "    #iterate through all file names in the directory\n",
    "    for name in glob.glob(path_to_files + \"/*\"):\n",
    "        #open file\n",
    "        f = open(name) \n",
    "\n",
    "        #load file as json file\n",
    "        data = json.load(f)\n",
    "        name = name.replace(path_to_files, \"\")\n",
    "        name = name.replace(\"\\\\\" , \"\")\n",
    "        id_ecg = name.replace(\".json\", \"\")    \n",
    "        pseudo_id = int(id_ecg.partition(\"_\")[0])\n",
    "        patient_id = int(keys.loc[keys[\"anonymous_id\"] == pseudo_id, \"original_patient_id\"])\n",
    "        \n",
    "        if remove_no_dna: \n",
    "        #check if genetic data is available for this patient, if not, won't be added to list of yes/not ajmaline tested\n",
    "            if pseudo_id not in genetic_tested: \n",
    "                no_dna.append(id_ecg)\n",
    "                continue   \n",
    "            \n",
    "        #check if ECG has a field acquisition date, \n",
    "        #check if date in this field corresponds to an ajmaline test date for that patient number\n",
    "        #if so store as ajmaline test, otherwise store as not tested: use for training\n",
    "        #if ECG has no field acquisition date, store ECG as having different format\n",
    "        if data[\"RestingECG\"].__contains__(\"TestDemographics\"):\n",
    "            t_demographics = data[\"RestingECG\"][\"TestDemographics\"]\n",
    "\n",
    "            if t_demographics.__contains__(\"AcquisitionDate\"):\n",
    "                \n",
    "                #put datetime in \"%m-%d-%Y\" format\n",
    "                test_date = str(t_demographics[\"AcquisitionDate\"])\n",
    "                datetime.date.strftime(pd.to_datetime(test_date), \"%m-%d-%Y\")\n",
    "\n",
    "                if test_date == dates[patient_id]:                \n",
    "                    ajmaline_tested.append(id_ecg)\n",
    "                else:\n",
    "                    not_tested.append(id_ecg) \n",
    "            else:\n",
    "                diff.append(id_ecg)\n",
    "        else:\n",
    "            diff.append(id_ecg)\n",
    "                    \n",
    "    return ajmaline_tested, not_tested, no_dna, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajmaline_tested = []\n",
    "not_tested = []\n",
    "no_dna = []\n",
    "diff = []\n",
    "\n",
    "ajmaline_tested, not_tested, no_dna, diff = filter_patients(path_positive, ajmaline_tested, not_tested, no_dna, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53404e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ajmaline_tested))\n",
    "print(len(not_tested))\n",
    "print(len(no_dna))\n",
    "print(len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79794ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ajmaline_tested, not_tested, no_dna, diff = filter_patients(path_negative, ajmaline_tested, not_tested, no_dna, diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ajmaline_tested))\n",
    "print(len(not_tested))\n",
    "print(len(no_dna))\n",
    "print(len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2579e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dna.sort()\n",
    "no_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ajmaline_tested) + len(not_tested) + len(no_dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ffda61",
   "metadata": {},
   "source": [
    "## Check that no patient number is more than one list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f9e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(set(not_tested).intersection(set(ajmaline_tested))))\n",
    "print(list(set(not_tested).intersection(set(no_dna))))\n",
    "print(list(set(no_dna).intersection(set(ajmaline_tested))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639cbd43",
   "metadata": {},
   "source": [
    "## Check there's 8 leads pp & check filter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70e9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lead_data(lead_data, diff_str, filename):\n",
    "    lead_I = []\n",
    "    lead_II = []\n",
    "    lead_V1 = []\n",
    "    lead_V2 = []\n",
    "    lead_V3 = []\n",
    "    lead_V4 = []\n",
    "    lead_V5 = []\n",
    "    lead_V6 = []\n",
    "    \n",
    "    lead_indx = {0: lead_I, 1: lead_II, 2: lead_V1, 3: lead_V2, 4: lead_V3,\n",
    "             5: lead_V4, 6: lead_V5, 7: lead_V6}\n",
    "    \n",
    "  \n",
    "    #find ECG data per lead and add offset\n",
    "    for index in lead_indx:\n",
    "        leadoffset = float(lead_data[1][index][\"LeadOffsetFirstSample\"])\n",
    "        \n",
    "        if np.isnan(leadoffset):\n",
    "            leadoffset = 0\n",
    "            \n",
    "        decoded = np.array(np.frombuffer(b64decode(lead_data[1][index][\"WaveFormData\"]), dtype=np.int16)) - leadoffset\n",
    "        lead_indx[index] = decoded\n",
    "        \n",
    "        #if lead length is not 2500 or 5000 save as file with different structure\n",
    "        if not (len(decoded) == 2500 or len(decoded) == 5000):\n",
    "            error = \"different sampling rate: \" + str(len(decoded))\n",
    "            diff_str.append({filename: error}) \n",
    "            continue\n",
    "            \n",
    "    return lead_indx[0], lead_indx[1], lead_indx[2], lead_indx[3], lead_indx[4], lead_indx[5], lead_indx[6], lead_indx[7], diff_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d91cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample leads measured at double speed\n",
    "#keeps values at every other index\n",
    "def downsample(lead):    \n",
    "    if len(lead) == 5000:\n",
    "        indeces = np.arange(0,5000,2)\n",
    "        downsampled = lead[indeces]\n",
    "        return downsampled\n",
    "    return lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store file name with corresponding directory\n",
    "def create_directories(json_file_names):\n",
    "    directories = []\n",
    "    for elem in json_file_names:\n",
    "        if elem[0] == str(1):\n",
    "            directory = path_negative + \"/\"+ elem\n",
    "            directories.append(directory)\n",
    "        if elem[0] == str(2):\n",
    "            directory = path_positive + \"/\" + elem\n",
    "            directories.append(directory)\n",
    "    return directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_process_data(list_of_ecg_ids):\n",
    "\n",
    "    json_ids = [sub + \".json\" for sub in list_of_ecg_ids]\n",
    "    directories = create_directories(json_ids)\n",
    "    transformed_files=0\n",
    "    filters = pd.DataFrame()\n",
    "    \n",
    "    for filename in directories:\n",
    "        f = open(filename)\n",
    "        data = json.load(f)\n",
    "        diff_str = []\n",
    "\n",
    "        ########## checks structure ##########\n",
    "        if (\"RestingECG\") in data:        \n",
    "            ecg = data[\"RestingECG\"]\n",
    "        else:\n",
    "            diff_str.append({filename: \"no RestingECG\"})\n",
    "            continue\n",
    "\n",
    "        if (\"Waveform\") in ecg:\n",
    "            waveform = pd.DataFrame(ecg[\"Waveform\"])\n",
    "        else:\n",
    "            diff_str.append({filename: \"no Waveform\"})\n",
    "            continue\n",
    "        ########## ################ ##########  \n",
    "\n",
    "        ########## gets lead data ##########        \n",
    "        if (\"WaveformType\") in waveform:\n",
    "            waveform_rhythm = pd.DataFrame(waveform[waveform[\"WaveformType\"]==\"Rhythm\"])\n",
    "\n",
    "            if waveform_rhythm.empty:\n",
    "                diff_str.append({filename: \"no Rhythm values\"})\n",
    "                continue\n",
    "\n",
    "            lead_data = waveform_rhythm[\"LeadData\"]\n",
    "            if lead_data.empty:\n",
    "                diff_str.append({filename: \"no LeadData\"})\n",
    "                continue\n",
    "\n",
    "            lead_I, lead_II, lead_V1, lead_V2, lead_V3, lead_V4, lead_V5, lead_V6, diff_str = get_lead_data(lead_data, diff_str, filename)       \n",
    "            \n",
    "\n",
    "        else:        \n",
    "            diff_str.append({filename: \"no WaveformType\"})\n",
    "            continue\n",
    "        ########## ################ ##########\n",
    "\n",
    "        ########### checks label pos or neg ##########\n",
    "        label = \"\"\n",
    "        if \"positive\" in filename:\n",
    "            label = \"positive\"\n",
    "        elif \"negative\" in filename:\n",
    "            label = \"negative\"\n",
    "        ########## ################ ##########\n",
    "\n",
    "        ########### saves filter type ##########    \n",
    "        temp = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": filename,\n",
    "            \"high_pass\": waveform_rhythm[\"HighPassFilter\"],\n",
    "            \"low_pass\": waveform_rhythm[\"LowPassFilter\"],\n",
    "            \"ac\": waveform_rhythm[\"ACFilter\"],\n",
    "            \"label\": label\n",
    "        })\n",
    "\n",
    "        filters = pd.concat([filters, temp])\n",
    "        ########## ################ ##########\n",
    "\n",
    "        transformed_files = transformed_files + 1\n",
    "        \n",
    "    return diff_str, filters, transformed_files\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_str, filters, transformed_files = check_and_process_data(not_tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_str, transformed_files) #diff_str is empty hence all samples have 2500 or 5000 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac893583",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "### Pos and Neg number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_filters = filters.loc[:, filters.columns != \"id\"]\n",
    "m = mini_filters.groupby([\"label\"]).size().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34184c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of positive samples, negative samples, and total\n",
    "tot_negatives = m.iloc[0,1]\n",
    "tot_positives = m.iloc[1,1]\n",
    "tot = tot_negatives + tot_positives\n",
    "print(tot_negatives, tot_positives, tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727559b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = m[\"Count\"]\n",
    "y_pos = np.arange(len(m[\"label\"]))\n",
    "plt.bar(y_pos, counts)\n",
    "plt.xticks(y_pos, m[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bedec3",
   "metadata": {},
   "source": [
    "### Number of patients per class AND Number of samples per patient per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9454e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped_not_tested = []\n",
    "for p in not_tested:\n",
    "     stripped_not_tested.append(p.split(\"_\", 1)[0]) #remove everythin after \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_patient = pd.DataFrame()\n",
    "for p in stripped_not_tested:\n",
    "    if p[0] == \"1\":\n",
    "        label = \"negative\"\n",
    "    if p[0] == \"2\":\n",
    "        label = \"positive\"\n",
    "        \n",
    "\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            \"id\": p,\n",
    "            \"label\": label\n",
    "        }, index = [0])\n",
    "    \n",
    "    samples_per_patient = pd.concat([samples_per_patient, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20202a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = samples_per_patient.groupby([\"id\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.groupby(\"label\")[\"Count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53033c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.groupby(\"label\")[\"Count\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30022202",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[m[\"label\"]==\"positive\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a18c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m[m[\"label\"]==\"negative\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823fba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"label\", y=\"Count\", data = m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3712280f",
   "metadata": {},
   "source": [
    "### Count and Percentage per class per (high, low, ac) filter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mini_filters.groupby([\"high_pass\", \"low_pass\", \"ac\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "m[\"percentage_by_class\"] = 100 * m[\"Count\"] / m.groupby(\"label\")[\"Count\"].transform(\"sum\")\n",
    "m[\"combination\"] = list(zip(m.high_pass, m.low_pass, m.ac))\n",
    "m.sort_values(by=[\"label\", \"percentage_by_class\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437f801",
   "metadata": {},
   "source": [
    "### Count and Percentage per class per high pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5688eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mini_filters.groupby([\"high_pass\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "m[\"percentage_by_class\"] = 100 * m[\"Count\"] / m.groupby(\"label\")[\"Count\"].transform(\"sum\")\n",
    "m.sort_values(by=[\"label\", \"percentage_by_class\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604e482",
   "metadata": {},
   "source": [
    "### Count and Percentage per class per low pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6202da",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mini_filters.groupby([\"low_pass\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "m[\"percentage_by_class\"] = 100 * m[\"Count\"] / m.groupby(\"label\")[\"Count\"].transform(\"sum\")\n",
    "m.sort_values(by=[\"label\", \"percentage_by_class\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71390f1",
   "metadata": {},
   "source": [
    "### Count and Percentage per class per ac filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mini_filters.groupby([\"ac\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "m[\"percentage_by_class\"] = 100 * m[\"Count\"] / m.groupby(\"label\")[\"Count\"].transform(\"sum\")\n",
    "m.sort_values(by=[\"label\", \"percentage_by_class\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d27d0",
   "metadata": {},
   "source": [
    "# II. Make Independent Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load old train_val_test dict and keep test samples that have genetic data\n",
    "\n",
    "#open train, val, test split used to train ECG only network\n",
    "with open(ecg_only_split_path, \"r\") as fp:\n",
    "    original_train_val_test_dict = json.load(fp)\n",
    "    \n",
    "original_test = original_train_val_test_dict[\"test\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e9deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(set(original_test).intersection(set(not_tested)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"samples in original test set: \", len(original_test), \", samples in new test set: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf52b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test patient pseudo ids\n",
    "pos_test = [str(elem.split(\"_\")[0]) for elem in test if elem[0]==str(2)]\n",
    "neg_test = [str(elem.split(\"_\")[0]) for elem in test if elem[0]==str(1)]\n",
    "test_ids = list(dict.fromkeys(pos_test)) + list(dict.fromkeys(neg_test))  \n",
    "pos_test =list(dict.fromkeys(pos_test))\n",
    "neg_test =list(dict.fromkeys(neg_test))\n",
    "print(\"number of positive test patients: \", len(pos_test),\", number of negative test patients: \", len(neg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_ecg_id = [elem for elem in test if elem[0]==str(2)]\n",
    "neg_test_ecg_id = [elem for elem in test if elem[0]==str(1)]\n",
    "print(\"number of positive test samples: \", len(pos_test_ecg_id),\", number of negative test samples: \", len(neg_test_ecg_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707cfc9c",
   "metadata": {},
   "source": [
    "# III. Make Train and Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ef4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = samples_per_patient.groupby([\"id\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_ecgs = m[m[\"label\"] == \"positive\"]\n",
    "neg_ecgs = m[m[\"label\"] == \"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61590477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all ecg file names that contain the substring corresponding to a pseudo patient id from test set ids\n",
    "not_tested = pd.DataFrame(not_tested)\n",
    "not_tested.columns = [\"ecg_id\"]\n",
    "not_tested = pd.Series(not_tested.ecg_id)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train_val_ids = pos_ecgs[~pos_ecgs[\"id\"].isin(pos_test)][\"id\"] #get all id's that are not in the test set\n",
    "neg_train_val_ids = neg_ecgs[~neg_ecgs[\"id\"].isin(neg_test)][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_ecgs[\"id\"]) + len(neg_ecgs[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_train_val_ids) + len(neg_train_val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf75ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_test) + len(neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_train_val_ids) + len(neg_train_val_ids) + len(pos_test) + len(neg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ce2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all ecg file names that contain the substring corresponding to a pseudo patient id from list of ids that are not in test set\n",
    "pos_train_val_ecg_id = []\n",
    "for patient_id in pos_train_val_ids:\n",
    "    patient_id = str(patient_id)    \n",
    "    ecgs = list(not_tested.loc[not_tested.str.contains(patient_id)].values)\n",
    "    for ecg_id in ecgs:\n",
    "        pos_train_val_ecg_id.append(ecg_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04ff739",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_train_val_ecg_id = []\n",
    "for patient_id in neg_train_val_ids:\n",
    "    patient_id = str(patient_id)    \n",
    "    ecgs = list(not_tested.loc[not_tested.str.contains(patient_id)].values)\n",
    "    for ecg_id in ecgs:\n",
    "        neg_train_val_ecg_id.append(ecg_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pos_train_val_ecg_id), len(neg_train_val_ecg_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pos_or_neg_val = round((len(pos_train_val_ecg_id) + len(neg_train_val_ecg_id))*0.05)\n",
    "pos_val = random.sample(pos_train_val_ecg_id, n_pos_or_neg_val)\n",
    "neg_val = random.sample(neg_train_val_ecg_id, n_pos_or_neg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train = list(set(pos_train_val_ecg_id).symmetric_difference(pos_val))\n",
    "neg_train = list(set(neg_train_val_ecg_id).symmetric_difference(neg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd84618",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train , val, test proportion out of total positive samples: \")\n",
    "print(len(pos_train)/tot_positives, len(pos_val)/tot_positives, len(pos_test_ecg_id)/tot_positives)\n",
    "print(\"\")\n",
    "print(\"train , val, test proportion out of total neagtive samples: \")\n",
    "print(len(neg_train)/tot_negatives, len(neg_val)/tot_negatives, len(neg_test_ecg_id)/tot_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d5a056",
   "metadata": {},
   "source": [
    "# IV. Check Filter Distribution in Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2ec1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_str, pos_train_filters, transformed_files = check_and_process_data(pos_train)\n",
    "diff_str, neg_train_filters, transformed_files = check_and_process_data(neg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4af69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_filter_dist(df): \n",
    "    filter_combo = df.groupby([\"high_pass\", \"low_pass\", \"ac\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "    filter_combo[\"percentage_by_class\"] = 100 * filter_combo[\"Count\"] / filter_combo.groupby(\"label\")[\"Count\"].transform(\"sum\")\n",
    "    filter_combo[\"combination\"] = list(zip(filter_combo.high_pass, filter_combo.low_pass, filter_combo.ac))\n",
    "    filter_combo = filter_combo.sort_values(by=[\"label\", \"percentage_by_class\"], ascending=False)\n",
    "    \n",
    "    return filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bce247",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo = analyse_filter_dist(pos_train_filters)\n",
    "n_filter_combo = analyse_filter_dist(neg_train_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d22520",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo_head = n_filter_combo.head(5)\n",
    "p_filter_combo_head = p_filter_combo.head(5)\n",
    "\n",
    "p_filter_combo_head = p_filter_combo_head.set_index(\"combination\")\n",
    "p_filter_combo_head = p_filter_combo_head.reindex(index = n_filter_combo_head[\"combination\"])\n",
    "p_filter_combo_head = p_filter_combo_head.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ddc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabe4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd87e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ab44a",
   "metadata": {},
   "source": [
    "## Top 5 filter combos per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(p_filter_combo_head.shape[0])\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12.5))\n",
    "rects_neg = ax.bar(ind - width/2, n_filter_combo_head[\"percentage_by_class\"], width, label = \"Negative\")\n",
    "rects_pos = ax.bar(ind + width/2, p_filter_combo_head[\"percentage_by_class\"], width, label = \"Positive\")\n",
    "ax.set_ylabel(\"Percentage of samples\")\n",
    "ax.set_title(\"Top 5 percentage of samples per filter combination per class\")\n",
    "ax.set_xticks(ind)\n",
    "y_labels = list(n_filter_combo_head[\"combination\"])\n",
    "ax.set_xticklabels(y_labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab422e45",
   "metadata": {},
   "source": [
    "## Difference in distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = pd.merge(n_filter_combo[[\"combination\", \"percentage_by_class\"]],\n",
    "                p_filter_combo[[\"combination\", \"percentage_by_class\"]],\n",
    "                how = \"outer\",\n",
    "                left_on = [\"combination\"],\n",
    "                right_on = [\"combination\"],\n",
    "                suffixes = [\"_neg\", \"_pos\"])\n",
    "\n",
    "diff1.fillna(0, inplace=True)\n",
    "diff1[\"difference\"] = diff1[\"percentage_by_class_neg\"]- diff1[\"percentage_by_class_pos\"]\n",
    "\n",
    "diff1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2c385",
   "metadata": {},
   "source": [
    "# V. Modify filter distribution in training set - change this if removing samples with no DNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1553a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biggest difference in (16,150, 50)\n",
    "#difference is approx 16%, want percentage differences to be at most 5% \n",
    "#decrease 16 150 50 until it's 13%\n",
    "\n",
    "goal = 0.13 #change this according to distribution differences found between classes in previous section\n",
    "total =  sum(n_filter_combo[\"Count\"]) \n",
    "n_sixteen_150_fifty = n_filter_combo[n_filter_combo[\"combination\"] == (\"16\", \"150\", \"50\")][\"Count\"].values[0]\n",
    "\n",
    "x = round((n_sixteen_150_fifty - goal*total) / (1-goal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (neg_train_filters[\"high_pass\"] == \"16\") & (neg_train_filters[\"low_pass\"] == \"150\") & (neg_train_filters[\"ac\"] == \"50\")\n",
    "sixteen_150_fifty = neg_train_filters[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1370c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_from_train = random.sample(list(sixteen_150_fifty[\"id\"]), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8bc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove directory and \".json\" to keep only file id\n",
    "remove_from_train_id = []\n",
    "substr = path_negative + \"/\"\n",
    "for file_id in remove_from_train:\n",
    "    file_id = file_id.split(substr, 1)[1]\n",
    "    file_id = file_id.split(\".json\", 1)[0]\n",
    "    remove_from_train_id.append(file_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_train_final = list(set(neg_train).symmetric_difference(remove_from_train_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_val:\n",
    "    neg_val_final = neg_val + remove_from_train_id\n",
    "else:    \n",
    "    neg_val_final = neg_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c73fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(neg_train), x, len(neg_train_final), len(neg_val), len(neg_val_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae9102",
   "metadata": {},
   "source": [
    "## Check data proportions per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_val:\n",
    "    tot_negatives = tot_negatives\n",
    "else:\n",
    "    tot_negatives = tot_negatives - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea31c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion train/val/test per class\n",
    "print(len(pos_train)/tot_positives, len(pos_val)/tot_positives, len(pos_test_ecg_id)/tot_positives)\n",
    "print(len(neg_train_final)/tot_negatives, len(neg_val_final)/tot_negatives, len(neg_test_ecg_id)/tot_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = tot_positives + tot_negatives\n",
    "\n",
    "#proportion train/val/test\n",
    "print((len(pos_train)+len(neg_train_final))/n, \n",
    "      (len(pos_val)+len(neg_val_final))/n,\n",
    "      (len(pos_test_ecg_id) + len(neg_test_ecg_id))/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322509e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive and negative samples in train val test\n",
    "print(len(pos_train),len(neg_train_final), \n",
    "      len(pos_val),len(neg_val_final),\n",
    "      len(pos_test_ecg_id), len(neg_test_ecg_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed17930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class imbalance before filter cleaning\n",
    "print(len(neg_train)/len(pos_train), len(neg_val)/len(pos_val), len(neg_test_ecg_id)/len(pos_test_ecg_id))\n",
    "#class imbalance after filter cleaning\n",
    "print(len(neg_train_final)/len(pos_train), len(neg_val_final)/len(pos_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c3ed7",
   "metadata": {},
   "source": [
    "# VI. Check Filter Distribution in Training Set after Redistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0007dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store file name with corresponding directory\n",
    "diff_str, neg_train_filters, transformed_files = check_and_process_data(neg_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30932210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get df with number of samples per filter combo\n",
    "n_filter_combo = analyse_filter_dist(neg_train_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b239d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 5 highest proportions per class and order with order of appearance for negative samples\n",
    "n_filter_combo_head = n_filter_combo.head(5)\n",
    "p_filter_combo_head = p_filter_combo.head(5)\n",
    "p_filter_combo_head = p_filter_combo_head.set_index(\"combination\")\n",
    "p_filter_combo_head = p_filter_combo_head.reindex(index = n_filter_combo_head[\"combination\"])\n",
    "p_filter_combo_head = p_filter_combo_head.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d429b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5708d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4bcf9",
   "metadata": {},
   "source": [
    "## Top 5 filter combos per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(p_filter_combo_head.shape[0])\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12.5))\n",
    "rects_neg = ax.bar(ind - width/2, n_filter_combo_head[\"percentage_by_class\"], width, label = \"Negative\")\n",
    "rects_pos = ax.bar(ind + width/2, p_filter_combo_head[\"percentage_by_class\"], width, label = \"Positive\")\n",
    "ax.set_ylabel(\"Percentage of samples\")\n",
    "ax.set_title(\"Top 5 percentage of samples per filter combination per class\")\n",
    "ax.set_xticks(ind)\n",
    "y_labels = list(n_filter_combo_head[\"combination\"])\n",
    "ax.set_xticklabels(y_labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50bb0c",
   "metadata": {},
   "source": [
    "## Difference in distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad117c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2 = pd.merge(n_filter_combo[[\"combination\", \"percentage_by_class\"]],\n",
    "                p_filter_combo[[\"combination\", \"percentage_by_class\"]],\n",
    "                how = \"outer\",\n",
    "                left_on = [\"combination\"],\n",
    "                right_on = [\"combination\"],\n",
    "                suffixes = [\"_neg\", \"_pos\"])\n",
    "\n",
    "diff2.fillna(0, inplace=True)\n",
    "diff2[\"difference\"] = diff2[\"percentage_by_class_neg\"]- diff2[\"percentage_by_class_pos\"]\n",
    "\n",
    "diff2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66def529",
   "metadata": {},
   "source": [
    "# VII. Data Processing - from here on, same code if delete samples with no DNA data\n",
    "\n",
    "## Get lead data, store as npy files, store labels, store dictionary with train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample leads measured at double speed\n",
    "#keeps values at every other index\n",
    "def downsample(lead):    \n",
    "    if len(lead) == 5000:\n",
    "        indeces = np.arange(0,5000,2)\n",
    "        downsampled = lead[indeces]\n",
    "        return downsampled\n",
    "    return lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_npy(file_id, file_directory, array):\n",
    "    file_name =  str(file_id) + \".npy\"\n",
    "    np.save(file_directory + \"/\" + file_name, array)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_save_data(list_of_ecg_ids, labels, pos_or_neg, samples_path):\n",
    "\n",
    "    json_ids = [sub + \".json\" for sub in list_of_ecg_ids]\n",
    "    directories = create_directories(json_ids)\n",
    "    \n",
    "    for filename in directories:\n",
    "        f = open(filename)\n",
    "        data = json.load(f)\n",
    "        diff_str = []\n",
    "        \n",
    "        if pos_or_neg == 0:\n",
    "            substr = path_negative + \"/\"\n",
    "        if pos_or_neg == 1:\n",
    "            substr = path_positive + \"/\"\n",
    "        \n",
    "        ecg_id = filename.split(substr, 1)[1]\n",
    "        ecg_id = ecg_id.split(\".json\", 1)[0]\n",
    "           \n",
    "        ecg = data[\"RestingECG\"]\n",
    "        waveform = pd.DataFrame(ecg[\"Waveform\"])\n",
    "        waveform_rhythm = pd.DataFrame(waveform[waveform[\"WaveformType\"]==\"Rhythm\"])\n",
    "        lead_data = waveform_rhythm[\"LeadData\"]\n",
    "        lead_I, lead_II, lead_V1, lead_V2, lead_V3, lead_V4, lead_V5, lead_V6, diff_str = get_lead_data(lead_data, diff_str, filename)       \n",
    "            \n",
    "        #downsample all leads with 5000 measurements to 2500 measurements   \n",
    "        lead_I = downsample(lead_I)\n",
    "        lead_II = downsample(lead_II)\n",
    "        lead_V1 = downsample(lead_V1)\n",
    "        lead_V2 = downsample(lead_V2)\n",
    "        lead_V3 = downsample(lead_V3)\n",
    "        lead_V4 = downsample(lead_V4)\n",
    "        lead_V5 = downsample(lead_V5)\n",
    "        lead_V6 = downsample(lead_V6)               \n",
    "\n",
    "        #put different time stamps as different rows\n",
    "        leads = np.array([lead_I, lead_II, lead_V1, lead_V2, lead_V3, lead_V4, lead_V5, lead_V6]).T\n",
    "\n",
    "        #save label in different list\n",
    "        labels.append([ecg_id, pos_or_neg])      \n",
    "\n",
    "        #check NaNs\n",
    "        if np.isnan(leads).any():\n",
    "            print(\"Warning: NaNs in sample \", filename)\n",
    "\n",
    "        #write to npy file\n",
    "        write_to_npy(ecg_id, samples_path, leads)\n",
    "        \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83223204",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = process_save_data(pos_train, [], 1, samples_path)\n",
    "labels = process_save_data(pos_val, labels, 1, samples_path)\n",
    "labels = process_save_data(pos_test_ecg_id, labels, 1, samples_path)\n",
    "labels = process_save_data(neg_train_final, labels, 0, samples_path)\n",
    "labels = process_save_data(neg_val_final, labels, 0, samples_path)\n",
    "labels = process_save_data(neg_test_ecg_id, labels, 0, samples_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save labels as npy file\n",
    "labels = np.array(labels)\n",
    "np.save(labels_path, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_dict = {\n",
    "        \"train\": pos_train + neg_train_final , \n",
    "        \"val\": pos_val + neg_val_final  , \n",
    "        \"test\": pos_test_ecg_id + neg_test_ecg_id}   \n",
    "\n",
    "#save indexes of train, val and test for future use\n",
    "with open(split_path, \"w\") as fp:\n",
    "    json.dump(train_val_test_dict, fp)\n",
    "fp.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a14336",
   "metadata": {},
   "source": [
    "# VIII. Example of Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ea24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.load(samples_path + \"20109_2.npy\")\n",
    "print(example.shape)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57795a",
   "metadata": {},
   "source": [
    "# IX. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_leads(file_id_nr):\n",
    "    df = np.load(samples_path + str(file_id_nr) + \".npy\")\n",
    "    \n",
    "    t = np.arange(df.shape[0])\n",
    "    fig, axis = plt.subplots(4, 2, sharex=True, sharey=True, figsize=(25, 20))\n",
    "    \n",
    "    axis[0,0].plot(t, df[:,0])\n",
    "    axis[0,0].set_title(\"Lead I\")\n",
    "    \n",
    "    axis[0,1].plot(t, df[:,1])\n",
    "    axis[0,1].set_title(\"Lead II\")\n",
    "    \n",
    "    axis[1,0].plot(t, df[:,2])\n",
    "    axis[1,0].set_title(\"Lead V1\")\n",
    "    \n",
    "    axis[1,1].plot(t, df[:,3])\n",
    "    axis[1,1].set_title(\"Lead V2\")\n",
    "    \n",
    "    axis[2,0].plot(t, df[:,4])\n",
    "    axis[2,0].set_title(\"Lead V3\")\n",
    "    \n",
    "    axis[2,1].plot(t, df[:,5])\n",
    "    axis[2,1].set_title(\"Lead V4\")\n",
    "    \n",
    "    axis[3,0].plot(t, df[:,6])\n",
    "    axis[3,0].set_title(\"Lead V5\")\n",
    "    \n",
    "    axis[3,1].plot(t, df[:,7])\n",
    "    axis[3,1].set_title(\"Lead V6\")\n",
    "    \n",
    "    name = \"plot_\" + str(file_id_nr)\n",
    "    #fig.savefig(name)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_leads(\"20109_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0ea59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
