{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67de3ee",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import gc\n",
    "import keras\n",
    "import mcfly\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6081361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record of the index of the first positive sample and the last positive sample\n",
    "indexes = pd.read_csv(\"Data/info/info.csv\")\n",
    "\n",
    "#paths to the labels and the data\n",
    "labels_path = \"Data/labels/labels.npy\"\n",
    "samples_path = \"Data/samples/\"\n",
    "\n",
    "#set to True if want to generate models, if already ran the script and have the models set to False\n",
    "generate_models = False\n",
    "\n",
    "\n",
    "#if generate_models = True, create paths to store model types, architectures and hyperparameters\n",
    "archi_path = \"Models/architecture/architecture_\"\n",
    "params_path = \"Models/parameters/params_\"\n",
    "type_path = \"Models/type/type_\"\n",
    "\n",
    "#set the seed \n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_postive_idx = indexes.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f56eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_postive_idx = indexes.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ad1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_indexes = range(first_postive_idx) #last number (first positive) is excluded\n",
    "positive_indexes = range(first_postive_idx, last_postive_idx + 1, 1) #add 1 to include last positive\n",
    "\n",
    "train_val_test_dict = {\n",
    "    \"train\": [], \n",
    "    \"val\": [], \n",
    "    \"test\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fc6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dictionary with train, validation and test set file indexes.\n",
    "#train_proportion is the desired proportion, expressed as a decimal in [0,1], of train samples.\n",
    "#val_proportion is the desired proportion, expressed as a decimal in [0,1], of validation samples.\n",
    "\n",
    "#done separately for positive and negative samples, e.g.: train set gets 80% of data.\n",
    "#80% of the negative samples and 80% of the positive samples make the train set.\n",
    "\n",
    "def draw_samples(file_indexes, train_val_test_dict, train_proportion, val_proportion):\n",
    "    \n",
    "    n_samples = len(file_indexes)\n",
    "    random_idx = random.sample(file_indexes, n_samples)\n",
    "    train_max_idx = round(train_proportion * n_samples)\n",
    "    val_max_idx = round((train_proportion + val_proportion) * n_samples)\n",
    "    \n",
    "    train = np.array(random_idx[0:train_max_idx + 1]).astype(str)\n",
    "    val = np.array(random_idx[train_max_idx +1  : val_max_idx +1 ]).astype(str)\n",
    "    test = np.array(random_idx[val_max_idx +1 : None]).astype(str)\n",
    "    \n",
    "    train = [\"id-\" + sub for sub in train]\n",
    "    val = [\"id-\" + sub for sub in val]\n",
    "    test = [\"id-\" + sub for sub in test]\n",
    "    \n",
    "    train_val_test_dict[\"train\"] = train_val_test_dict[\"train\"] + train\n",
    "    train_val_test_dict[\"val\"] = train_val_test_dict[\"val\"] + val\n",
    "    train_val_test_dict[\"test\"] = train_val_test_dict[\"test\"] + test \n",
    "            \n",
    "    return train_val_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99021878",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_dict = draw_samples(negative_indexes, train_val_test_dict, 0.8, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd32ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_dict = draw_samples(positive_indexes, train_val_test_dict, 0.8, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d74f8",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0957461",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_val_test_dict[\"train\"]))\n",
    "print(len(train_val_test_dict[\"val\"]))\n",
    "print(len(train_val_test_dict[\"test\"]))\n",
    "print(len(train_val_test_dict[\"train\"]) + len(train_val_test_dict[\"val\"]) + len(train_val_test_dict[\"test\"]))\n",
    "print(last_postive_idx +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc71787",
   "metadata": {},
   "source": [
    "# Generate McFly Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648dae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_models:\n",
    "    X_train_shape = (len(train_val_test_dict[\"train\"]), 2500, 8)\n",
    "    models = mcfly.modelgen.generate_models(X_train_shape, \n",
    "                                           number_of_classes = 2,\n",
    "                                           number_of_models = 10,\n",
    "                                           metrics = [\"accuracy\"])\n",
    "    \n",
    "    models_to_print = range(len(models))\n",
    "    for i, item in enumerate(models):\n",
    "        if i in models_to_print:\n",
    "            model, params, model_types = item\n",
    "            print(\"--------------------------------------------------------------------\")\n",
    "            print(\"Model\" + str(i))\n",
    "            print(\"  \")\n",
    "            print(\"Hyperparameters:\")\n",
    "            print(params)\n",
    "            print(\"  \")\n",
    "            print(\"Model description:\")\n",
    "            model.summary()\n",
    "            print(\"  \")\n",
    "            print(\"Model type:\")\n",
    "            print(model_types)\n",
    "            print(\" \") \n",
    "\n",
    "            for key, value in params.items():\n",
    "                if isinstance(value, np.ndarray):\n",
    "                    params[key] = value.tolist()\n",
    "\n",
    "            name = \"Model\" + str(i)\n",
    "            model_type = {\"type\": model_types}\n",
    "\n",
    "            with open(archi_path + name + \".json\", \"w\") as f:\n",
    "                json.dump(model.to_json(), f)\n",
    "\n",
    "            with open(params_path + name + \".json\", \"w\") as f:\n",
    "                json.dump(params, f)\n",
    "\n",
    "            with open(type_path + name + \".json\", \"w\") as f:\n",
    "                json.dump(model_type, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f948e",
   "metadata": {},
   "source": [
    "# Dictionary with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = np.load(labels_path)\n",
    "labels = dict()\n",
    "\n",
    "for row in labels_array:\n",
    "    labels[row[0]] = int(row[1])\n",
    "\n",
    "del labels_array\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92de56",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69f0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):    \n",
    "\n",
    "    def __init__(self, list_IDs, labels, batch_size = 32, dim = (2500, 8), n_channels = 1, n_classes=2, shuffle = True):\n",
    "        #\"Initialization\"\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        #number of batches per epoch\n",
    "        return int(np.floor(len(self.list_IDs)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #Generates indexes of one batch of data\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        #find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        \n",
    "        #Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        #updates indexes after each epoch\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        #Generates data containing batch_size samples\n",
    "        \n",
    "        #Initialise\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size), dtype = int)\n",
    "        \n",
    "        #Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            #store sample\n",
    "            X[i,] = np.load( samples_path + ID +\".npy\")\n",
    "            \n",
    "            #store class\n",
    "            y[i] = self.labels[ID]\n",
    "        \n",
    "        return X, keras.utils.to_categorical(y, num_classes = self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define parameters\n",
    "params = {\"dim\" : (2500, 8),\n",
    "         \"batch_size\": 32,\n",
    "         \"n_classes\": 2,\n",
    "         \"n_channels\":1,\n",
    "         \"shuffle\" :True}\n",
    "\n",
    "#batch loader on entire validation set\n",
    "params_val = {\"dim\" : (2500, 8),\n",
    "         \"batch_size\": len(train_val_test_dict[\"val\"]),\n",
    "         \"n_classes\": 2,\n",
    "         \"n_channels\":1,\n",
    "         \"shuffle\" :False}\n",
    "\n",
    "#Generators \n",
    "training_generator = DataGenerator(train_val_test_dict[\"train\"], labels, **params)\n",
    "validation_generator = DataGenerator(train_val_test_dict[\"val\"], labels, **params_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798ec45",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1910ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(archi_path + \"Model0.json\", \"r\") as f:\n",
    "    model_loaded = json.load(f)\n",
    "    model = keras.models.model_from_json(model_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c372553",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"]) #add learning rate here, regularisation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor = \"loss\", patience = 4)\n",
    "\n",
    "model.fit(training_generator, \n",
    "          validation_data = validation_generator, \n",
    "          epochs = 50,\n",
    "          class_weight = {0:1.,1:4.}, \n",
    "          callbacks = callback,\n",
    "          verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c631b",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d084181",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
