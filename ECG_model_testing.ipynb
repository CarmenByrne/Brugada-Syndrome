{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import gc\n",
    "import keras\n",
    "import mcfly\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import auc, roc_curve, precision_recall_curve, brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "from datetime import datetime \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c36f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to file with indexes of files split into training, val and test\n",
    "split_path = \"400_dumped/Final_Data/split/train_val_test.json\"\n",
    "\n",
    "#paths to the labels and the data\n",
    "labels_path = \"400_dumped/Final_Data/labels/labels.npy\"\n",
    "samples_path = \"400_dumped/Final_Data/samples/\"\n",
    "\n",
    "#choose model to laod and train\n",
    "model_name = \"Model6.json\"\n",
    "trained_path = \"400_dumped/Models_Final_Data/trained/\" + model_name\n",
    "type_path = \"400_dumped/Models_Final_Data/type/type_\"\n",
    "\n",
    "#path to save plots\n",
    "model_name_no_extension = model_name.split(\".\", 1)[0] + \"/\"\n",
    "plot_path = \"400_dumped/TestPlots/\" +  model_name_no_extension\n",
    "\n",
    "#path to original json data, to check filter types\n",
    "path_negative = \"AnonymisedECGs_json/negative\"\n",
    "path_positive = \"AnonymisedECGs_json/positive\"\n",
    "\n",
    "#set to true to save plots\n",
    "save_plots = False\n",
    "\n",
    "#set the seed \n",
    "random.seed(0) #generation of train, val, test sets\n",
    "np.random.seed(0) #mcfly models\n",
    "tf.random.set_seed(0) #keras training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de053c59",
   "metadata": {},
   "source": [
    "# Dictionary with sample id and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b60d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = np.load(labels_path)\n",
    "labels = dict()\n",
    "\n",
    "for row in labels_array:\n",
    "    labels[row[0]] = int(row[1])\n",
    "\n",
    "    \n",
    "del labels_array\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d6c3f",
   "metadata": {},
   "source": [
    "# Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01146177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open original train, val, test split to calculate original weights\n",
    "with open(split_path, \"r\") as fp:\n",
    "    train_val_test_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fe83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_val_test_dict[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6bd17",
   "metadata": {},
   "source": [
    "# Test set selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb73bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_val_test_dict[\"test\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77bcc20",
   "metadata": {},
   "source": [
    "# Check filter distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3787ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_filters = pd.DataFrame()\n",
    "neg_filters = pd.DataFrame()\n",
    "\n",
    "for elem in test: \n",
    "    \n",
    "    if elem[0] == str(1):\n",
    "            directory = path_negative + \"/\"+ elem + \".json\"\n",
    "            \n",
    "    if elem[0] == str(2):\n",
    "        directory = path_positive + \"/\" + elem + \".json\"\n",
    "    \n",
    "    f = open(directory)\n",
    "    data = json.load(f)\n",
    "        \n",
    "    ecg = data[\"RestingECG\"]\n",
    "    waveform = pd.DataFrame(ecg[\"Waveform\"])\n",
    "    waveform_rhythm = pd.DataFrame(waveform[waveform[\"WaveformType\"]==\"Rhythm\"])\n",
    "    \n",
    "    label = \"\"\n",
    "    if \"positive\" in directory:\n",
    "        label = \"positive\"\n",
    "    elif \"negative\" in directory:\n",
    "        label = \"negative\"\n",
    "    \n",
    "    temp = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": elem, \n",
    "        \"high_pass\": waveform_rhythm[\"HighPassFilter\"],\n",
    "        \"low_pass\": waveform_rhythm[\"LowPassFilter\"],\n",
    "        \"ac\": waveform_rhythm[\"ACFilter\"],\n",
    "        \"label\": label\n",
    "    })\n",
    "    \n",
    "    if label == \"positive\":\n",
    "        pos_filters = pd.concat([pos_filters, temp])\n",
    "    elif label == \"negative\":\n",
    "        neg_filters = pd.concat([neg_filters, temp])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08bfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_filter_dist(df): \n",
    "    filter_combo = df.groupby([\"high_pass\", \"low_pass\", \"ac\", \"label\"]).size().reset_index(name=\"Count\")\n",
    "    filter_combo[\"percentage_by_class\"] = 100 * filter_combo[\"Count\"] / filter_combo.groupby(\"label\")[\"Count\"].transform(\"sum\")\n",
    "    filter_combo[\"combination\"] = list(zip(filter_combo.high_pass, filter_combo.low_pass, filter_combo.ac))\n",
    "    filter_combo = filter_combo.sort_values(by=[\"label\", \"percentage_by_class\"], ascending=False)\n",
    "    \n",
    "    return filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b89ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo = analyse_filter_dist(pos_filters)\n",
    "n_filter_combo = analyse_filter_dist(neg_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a644ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c430564",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_negatives = np.sum(n_filter_combo[\"Count\"])\n",
    "number_positives = np.sum(p_filter_combo[\"Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc96242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class imbalance \n",
    "class_imb = number_negatives / number_positives\n",
    "\n",
    "#fraction of positives\n",
    "pos_fraction = number_positives / (number_positives + number_negatives)\n",
    "print(class_imb, pos_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781df9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo = n_filter_combo.set_index(\"combination\")\n",
    "n_filter_combo = n_filter_combo.reindex(index = p_filter_combo[\"combination\"])\n",
    "n_filter_combo = n_filter_combo.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b636281",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo_head = n_filter_combo.head(5)\n",
    "p_filter_combo_head = p_filter_combo.head(5)\n",
    "\n",
    "p_filter_combo_head = p_filter_combo_head.set_index(\"combination\")\n",
    "p_filter_combo_head = p_filter_combo_head.reindex(index = n_filter_combo_head[\"combination\"])\n",
    "p_filter_combo_head = p_filter_combo_head.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(p_filter_combo_head.shape[0])\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 12.5))\n",
    "rects_neg = ax.bar(ind - width/2, n_filter_combo_head[\"percentage_by_class\"], width, label = \"Negative\")\n",
    "rects_pos = ax.bar(ind + width/2, p_filter_combo_head[\"percentage_by_class\"], width, label = \"Positive\")\n",
    "ax.set_ylabel(\"Percentage of samples\")\n",
    "ax.set_title(\"Top 5 percentage of samples per filter combination per class\")\n",
    "ax.set_xticks(ind)\n",
    "y_labels = list(n_filter_combo_head[\"combination\"])\n",
    "ax.set_xticklabels(y_labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = pd.merge(n_filter_combo[[\"combination\", \"percentage_by_class\"]],\n",
    "                p_filter_combo[[\"combination\", \"percentage_by_class\"]],\n",
    "                how = \"left\",\n",
    "                left_on = [\"combination\"],\n",
    "                right_on = [\"combination\"],\n",
    "                suffixes = [\"_neg\", \"_pos\"])\n",
    "diff1[\"difference\"] = diff1[\"percentage_by_class_neg\"]- diff1[\"percentage_by_class_pos\"]\n",
    "diff1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec1a8fd",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create validation and test sets and store in memory\n",
    "def set_generation(val_or_test, train_val_test_dict, labels, dim = (2500, 8)):\n",
    "    n_samples = len(train_val_test_dict[val_or_test])\n",
    "\n",
    "    #Initialise\n",
    "    X = np.empty((n_samples, dim[0], dim[1]))\n",
    "    y = np.empty((n_samples), dtype = int)\n",
    "\n",
    "    #Generate data\n",
    "    for i, ID in enumerate(train_val_test_dict[val_or_test]):\n",
    "        #store sample\n",
    "        X[i,] = np.load(samples_path + ID +\".npy\")\n",
    "\n",
    "        #store class\n",
    "        y[i] = labels[ID]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1051edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(y_true, y_pred, y_proba, metrics):\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(conf_mat)\n",
    "    tn,fp,fn,tp = conf_mat.ravel()\n",
    "    print(\"tn: \", tn,\" fp: \", fp,\" fn: \", fn,\" tp: \", tp)\n",
    "    \n",
    "    print(\"\")\n",
    "    matthews = ((tp*tn) - (fp*fn)) / math.sqrt(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    print(\"Matthews Correlation Coefficient: \", matthews)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(\"\")           \n",
    "    precision_bis = tp/(tp+fp) #positive predictive value\n",
    "    recall_bis = tp/(tp+fn)\n",
    "    f1 = 2*precision_bis*recall_bis/(precision_bis+recall_bis)\n",
    "    specificity = tn/(tn+fp) #true negative rate\n",
    "    fnr = fn/(fn+tp)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    \n",
    "    print(\"precision/positive predictive value: \", precision_bis)\n",
    "    print(\"recall/sensitivity: \", recall_bis)\n",
    "    print(\"specificity/true negative rate: \", specificity)\n",
    "    print(\"False negative rate: \", fnr)\n",
    "    print(\"accuracy: \", accuracy)    \n",
    "    print(\"f1 score: \", f1) \n",
    "\n",
    "      \n",
    "    print(\"\")\n",
    "    brier = brier_score_loss(y_true, y_proba)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "    auc_coef = auc(fpr, tpr)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    auprc = auc(recall, precision)\n",
    "    print(\"brier score: \", brier )\n",
    "    print(\"auc: \", auc_coef)\n",
    "    print(\"auprc: \", auprc)\n",
    "    \n",
    "    metrics.append([tn, fp, fn, tp, matthews, precision_bis, recall_bis, specificity, fnr, accuracy, f1, auc_coef, auprc, brier])\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "#predicts on cv test set and gets performance stats\n",
    "def predictions(model, X_test, y_test, metrics):\n",
    "    pred_probas = model.predict(X_test)\n",
    "\n",
    "    #BrS appears as 1, hence transformed to [0,1] => the second column returns 1 if BrS, 0 otherwise\n",
    "    BrS = y_test[:,1]\n",
    "    \n",
    "    #get probabilities and predictions\n",
    "    BrS_probas = pred_probas[:,1]\n",
    "    BrS_predictions = pred_probas.argmax(axis = -1)\n",
    "    BrS_predictions\n",
    "    \n",
    "    #get performance metrics\n",
    "    performance_metrics(BrS, BrS_predictions, BrS_probas, metrics)\n",
    "    \n",
    "    return BrS, pred_probas, BrS_probas, BrS_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af80d1",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bfbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained model \n",
    "model = keras.models.load_model(trained_path)\n",
    "\n",
    "#generate test set and save to memory\n",
    "X_test, y_test = set_generation(\"test\", train_val_test_dict, labels, (2500, 8))\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "#predict and get performance metrics\n",
    "metrics = []\n",
    "BrS, pred_probas, BrS_probas, BrS_predictions = predictions(model, X_test, y_test, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0df83",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(type_path + model_name, \"r\") as f:\n",
    "    model_type = json.load(f)    \n",
    "    print(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(BrS, BrS_probas)\n",
    "auc_coef = round(auc(fpr, tpr),3)\n",
    "f, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(fpr, tpr, marker=\".\", label = model_type[\"type\"] + \" - AUC: \" + str(auc_coef))\n",
    "ax.plot([0,1], [0,1], transform = ax.transAxes, linestyle=\"--\", label=\"Random Classifier\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "#ax.set_title(\"ROC\")\n",
    "ax.legend()\n",
    "if save_plots:\n",
    "    plt.savefig(plot_path + \"ROC.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b98f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(BrS, BrS_probas)\n",
    "auprc = round(auc(recall, precision),3)\n",
    "f, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(recall, precision, marker=\".\", label = model_type[\"type\"] + \" - AUPRC: \" + str(auprc))\n",
    "ax.set_xlabel(\"Recall (Positive label: Brugada)\")\n",
    "ax.set_ylabel(\"Precision (Positive label: Brugada)\")\n",
    "#ax.set_title(\"AUPRC\")\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.legend()\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(plot_path + \"PrecisionRecallCurve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibration\n",
    "# bin data and normalise counts\n",
    "def counts_to_percentages(probabilities):\n",
    "    bin0_01 = 0\n",
    "    bin01_02=0\n",
    "    bin02_03=0\n",
    "    bin03_04=0\n",
    "    bin04_05=0\n",
    "    bin05_06=0\n",
    "    bin06_07=0\n",
    "    bin07_08=0\n",
    "    bin08_09=0\n",
    "    bin09_1=0 \n",
    "    \n",
    "    for val in probabilities:\n",
    "    \n",
    "        if val <0.1:\n",
    "            bin0_01 = bin0_01 + 1\n",
    "    \n",
    "        elif val >= 0.1 and val <0.2:\n",
    "            bin01_02= bin01_02 +1 \n",
    "    \n",
    "        elif val >= 0.2 and val <0.3:\n",
    "            bin02_03= bin02_03 +1 \n",
    "    \n",
    "        elif val >= 0.3 and val <0.4:\n",
    "                bin03_04= bin03_04 +1\n",
    "    \n",
    "        elif val >= 0.4 and val <0.5:\n",
    "                bin04_05= bin04_05 +1 \n",
    "    \n",
    "        elif val >= 0.5 and val <0.6:\n",
    "                bin05_06= bin05_06 +1 \n",
    "    \n",
    "        elif val >= 0.6 and val <0.7:\n",
    "                    bin06_07= bin06_07 +1 \n",
    "    \n",
    "        elif val >= 0.7 and val <0.8:\n",
    "                    bin07_08= bin07_08 +1 \n",
    "    \n",
    "        elif val >= 0.8 and val <0.9:\n",
    "                    bin08_09= bin08_09 +1 \n",
    "    \n",
    "        elif val >= 0.9:\n",
    "                    bin09_1= bin09_1 +1 \n",
    "                \n",
    "    counts = [bin0_01, bin01_02, bin02_03, bin03_04, bin04_05,\n",
    "             bin05_06, bin06_07, bin07_08, bin08_09, bin09_1]    \n",
    "    \n",
    "    percentages = counts/np.sum(counts) *100\n",
    "    \n",
    "    return percentages\n",
    "    \n",
    "    \n",
    "#plot calibration plot and histogram together\n",
    "def calibration_together (BrS, BrS_probas, per_patient = False):        \n",
    "    print(\"plot curves and save in one png file\")\n",
    "    #save three plots in one png file\n",
    "    fig_index = 1\n",
    "      \n",
    "    #save three plots in one png file\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(7, 12))   \n",
    "    \n",
    "    # plot calibration \n",
    "    y, x = calibration_curve(BrS, BrS_probas, n_bins=10)\n",
    "\n",
    "    ax1.plot(x, y, 'C0',marker='o', linewidth=1, label= model_type[\"type\"], color = \"darkturquoise\") \n",
    "    ax1.set(xlabel= 'Predicted score', ylabel= 'True probability in each bin')\n",
    "    \n",
    "    line = mlines.Line2D([0, 1], [0, 1], color='black', linestyle='--', linewidth=0.9, label= \"Perfectly calibrated\")\n",
    "    transform = ax1.transAxes\n",
    "    line.set_transform(transform)\n",
    "    ax1.add_line(line)     \n",
    "    ax1.legend(loc=\"upper left\")  \n",
    "  \n",
    "    #HISTOGRAMS    \n",
    "    x = np.arange(0,1,0.1)\n",
    "    y = counts_to_percentages(BrS_probas)   #if instead of % want values in [0,1], do: y = counts_to_percentages(proba)/100 \n",
    "    ax2.hist(x, range = [0,1], bins=10, weights = y, label= model_type[\"type\"],\n",
    "                 histtype=\"step\", lw=3.5, color = \"darkturquoise\")\n",
    "    \n",
    "    ax2.set_xlabel(\"Mean predicted score\")\n",
    "    ax2.set_ylabel(\"Percentage of counts\")\n",
    "    ax2.legend(loc=\"upper center\", ncol=5)\n",
    "    ax2.set_ylim([0,101]) #if instead of % want probabilities, change to [0,1]     \n",
    "\n",
    "    #plt.tight_layout()\n",
    "    if per_patient: \n",
    "        plt.savefig(plot_path + \"Calibration_PP.png\")\n",
    "        \n",
    "    elif save_plots:\n",
    "        plt.savefig(plot_path + \"Calibration.png\")\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "calibration_together(BrS, BrS_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df488a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrimination\n",
    "def distribution(BrS, BrS_probas, per_patient = False):\n",
    "    #probabilities distributions graphs\n",
    "    true_1 = pd.DataFrame(BrS_probas, columns=['Predicted probabilities'])\n",
    "    true_1['labels'] = BrS.tolist()\n",
    "    true_0 = true_1.copy(deep = True) \n",
    "    indexNames = true_1[true_1['labels'] == 0].index\n",
    "    true_1.drop(indexNames , inplace=True)\n",
    "    indexNames = true_0[ true_0['labels'] == 1 ].index\n",
    "    true_0.drop(indexNames , inplace=True)\n",
    "    true_1.drop(columns=['labels'], inplace = True)\n",
    "    true_0.drop(columns=['labels'], inplace = True)\n",
    "    \n",
    "    sns.distplot(true_1['Predicted probabilities'], hist = False, kde = True,\n",
    "                 kde_kws = {'shade': True, 'linewidth': 3,\"color\": \"r\"}, label = 'Class 1')\n",
    "    sns.distplot(true_0['Predicted probabilities'], hist = False, kde = True,\n",
    "                     kde_kws = {'shade': True, 'linewidth': 3, \"color\": \"g\"}, label = 'Class 0')\n",
    "    plt.ylabel('Density')\n",
    "    plt.xlabel('Predicted score')\n",
    "    plt.legend(labels=[\"BrP\",\"No BrP\"])\n",
    "    \n",
    "    if per_patient: \n",
    "        plt.savefig(plot_path + \"Discrimination_PP.png\")\n",
    "        \n",
    "    elif save_plots:\n",
    "        plt.savefig(plot_path + \"Discrimination.png\")  \n",
    "        \n",
    "        \n",
    "    plt.show()\n",
    "    plt.clf()    \n",
    "    return\n",
    "\n",
    "distribution(BrS, BrS_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e182bc",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451da722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import explanation\n",
    "from lime import lime_base\n",
    "from lime_timeseries import LimeTimeSeriesExplainer\n",
    "\n",
    "def custom_predict(trained_model):\n",
    "    #puts sample in right format for keras prediction\n",
    "    def func(sample):\n",
    "        prediction = trained_model.predict(np.transpose(sample, axes=[0,2,1]))\n",
    "        return prediction\n",
    "    return func\n",
    "\n",
    "def explain_sample_lime(explainer,series_ecg, num_features_ecg, n_samples, num_slices_ecg, replacement_method, predict_function = custom_predict(trained_model=model)):\n",
    "    \n",
    "    exp = explainer.explain_instance(series_ecg, predict_function, num_features=num_features_ecg, num_samples=n_samples, \n",
    "                                 num_slices=num_slices_ecg, replacement_method = \"total_mean\")\n",
    "    \n",
    "    fig = exp.as_pyplot_figure() \n",
    "    \n",
    "    return exp, fig\n",
    "\n",
    "def plot_lime(series_ecg, num_slices_ecg, X_val, y_val, BrS_predictions, idx_ecg, exp):\n",
    "\n",
    "    values_per_slice_ecg = math.ceil(series_ecg.shape[1]/ num_slices_ecg)\n",
    "    no_pattern = X_val[np.where(y_val[:,1]==0)]\n",
    "    pattern = X_val[np.where(y_val[:,1]==1)]\n",
    "    lead_to_index = {\"I\": 0, \"II\": 1, \"V1\": 2, \"V2\":3,\n",
    "                    \"V3\": 4, \"V4\": 5, \"V5\": 6, \"V6\":7}\n",
    "    leads = [\"I\", \"II\", \"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"]\n",
    "\n",
    "    labels = [\"no Brugada Pattern\", \"Brugada Pattern\"]\n",
    "    true_label = labels[int(y_val[idx_ecg,1])]\n",
    "    predicted_label = labels[BrS_predictions[idx_ecg]]\n",
    "\n",
    "    fig, axes = plt.subplots(nrows = 4, ncols = 2, figsize = (30,30), sharex = True, sharey=True)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.plot(series_ecg[i], 'b', label='Explained instance')\n",
    "        ax.plot(no_pattern[:,:,i].mean(axis=0), color='red',label='Mean of class no Brugada Pattern')\n",
    "        ax.plot(pattern[:,:,i].mean(axis=0), color='green',label='Mean of class Brugada Pattern')\n",
    "        ax.set_title(\"Lead \"+ leads[i], fontsize = 25)\n",
    "\n",
    "        for j in range(num_features_ecg):\n",
    "            feature, weight = exp.as_list()[j]        \n",
    "            feature_name_index = lead_to_index[feature.split(\" \", 2)[2]] #split at second space in feature name to take lead name as key\n",
    "\n",
    "            if feature_name_index == i:\n",
    "                start = int(feature.split(\" \", 1)[0]) * values_per_slice_ecg #int(feature.split(\" \", 1)[0]): only keep int from feature name, eg feature name (23 - II), split at \" \" (space) and keep first part (23) and take int(23)\n",
    "                end = start + values_per_slice_ecg\n",
    "                color = 'red' if weight < 0 else 'green' \n",
    "                ax.axvspan(start , end, color=color, alpha=abs(weight*10))\n",
    "\n",
    "    ax.legend(loc='lower left')\n",
    "    title = \"LIME explanation of single sample. True label: \" + true_label + \" . Predicted label: \" + predicted_label + \".\"\n",
    "    fig.suptitle(title, fontsize=50)\n",
    "    \n",
    "    if true_label == \"no Brugada Pattern\" and predicted_label == \"no Brugada Pattern\":\n",
    "        saved_title = \"True_negative.png\"\n",
    "    elif true_label == \"no Brugada Pattern\" and predicted_label == \"Brugada Pattern\":\n",
    "        saved_title = \"False_positive.png\"\n",
    "    elif true_label == \"Brugada Pattern\" and predicted_label == \"no Brugada Pattern\":\n",
    "        saved_title = \"False_negative.png\"\n",
    "    elif true_label == \"Brugada Pattern\" and predicted_label == \"Brugada Pattern\":\n",
    "        saved_title = \"True_positive.png\"\n",
    "        \n",
    "    plt.rc(\"axes\", labelsize=25)\n",
    "    plt.rc(\"legend\", fontsize=20)\n",
    "    \n",
    "    #fig.savefig(plot_path + saved_title)\n",
    "    plt.show()\n",
    "            \n",
    "    return fig\n",
    "\n",
    "#interpretation: real label is no BrP but model predicts as Brugada (false positive). Green bands correspond to\n",
    "# evidence that it's a positive sample, red bands correspond to evidence that it's a negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ad642",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_ecg = 100 #number of lime weights\n",
    "num_slices_ecg = 50 #number of segments of a lead\n",
    "n_samples = 50 #number of perturbated samples at a single time point\n",
    "replacement_method = \"total_mean\" #possible replacement mathods: \"noise\" (fill in noise for perturbation), \"mean\" (fill in mean of segment), \"total_mean\" (fill in mean of lead)\n",
    "explainer = LimeTimeSeriesExplainer(class_names = [\"No BrP\", \"BrP\"], signal_names= [\"I\", \"II\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca421c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp\n",
    "idx_ecg = 0 #0th sample\n",
    "series_ecg = X_test[idx_ecg].T\n",
    "exp, weights_fig = explain_sample_lime(explainer,series_ecg, num_features_ecg, n_samples, num_slices_ecg, replacement_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2c99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lime(series_ecg, num_slices_ecg, X_test, y_test, BrS_predictions, idx_ecg, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806adf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_ecg = 10 #number of lime weights\n",
    "num_slices_ecg = 50 #number of segments of a lead\n",
    "n_samples = 50 #number of perturbated samples at a single time point\n",
    "replacement_method = \"total_mean\" #possible replacement mathods: \"noise\" (fill in noise for perturbation), \"mean\" (fill in mean of segment), \"total_mean\" (fill in mean of lead)\n",
    "explainer = LimeTimeSeriesExplainer(class_names = [\"No BrP\", \"BrP\"], signal_names= [\"I\", \"II\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed568fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp\n",
    "idx_ecg = 0 #0th sample\n",
    "series_ecg = X_test[idx_ecg].T\n",
    "exp, weights_fig = explain_sample_lime(explainer,series_ecg, num_features_ecg, n_samples, num_slices_ecg, replacement_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lime(series_ecg, num_slices_ecg, X_test, y_test, BrS_predictions, idx_ecg, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp\n",
    "idx_ecg = 1 #nth sample\n",
    "series_ecg = X_test[idx_ecg].T\n",
    "exp, weights_fig = explain_sample_lime(explainer,series_ecg, num_features_ecg, n_samples, num_slices_ecg, replacement_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lime(series_ecg, num_slices_ecg, X_test, y_test, BrS_predictions, idx_ecg, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c25817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn\n",
    "idx_ecg = 56 #nth sample\n",
    "series_ecg = X_test[idx_ecg].T\n",
    "exp, weights_fig = explain_sample_lime(explainer,series_ecg, num_features_ecg, n_samples, num_slices_ecg, replacement_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lime(series_ecg, num_slices_ecg, X_test, y_test, BrS_predictions, idx_ecg, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1d767",
   "metadata": {},
   "source": [
    "# Label reproducibility per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e426aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped= []\n",
    "for p in test:\n",
    "     stripped.append(p.split(\"_\", 1)[0]) #remove everythin after \"_\"\n",
    "\n",
    "stripped = list(dict.fromkeys(stripped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c4accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test)\n",
    "test_df.columns = [\"ecg_id\"]\n",
    "test_df = pd.Series(test_df.ecg_id) \n",
    "dim = (2500, 8)\n",
    "mini_x = np.empty((1, dim[0], dim[1]))\n",
    "\n",
    "file_id_conf_mat = {\"TN\":[], \"TP\":[], \"FN\": [], \"FP\":[]}\n",
    "p_id_reprod = {}\n",
    "\n",
    "for p in stripped:\n",
    "    all_samples =  list(test_df.loc[test_df.str.contains(p)].values)\n",
    "    TP=0\n",
    "    TN=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    \n",
    "    for s in all_samples:\n",
    "        \n",
    "        mini_x[0,] = np.load(samples_path + s +\".npy\")\n",
    "        mini_y = labels[s] \n",
    "        if mini_y == 0: \n",
    "            mini_y = [1,0]\n",
    "        if mini_y == 1:\n",
    "            mini_y = [0,1]\n",
    "   \n",
    "        #predict and get performance metrics    \n",
    "        mini_pred_probas = model.predict(mini_x)\n",
    "\n",
    "        #BrS appears as 1, hence transformed to [0,1] => the second column returns 1 if BrS, 0 otherwise\n",
    "        mini_BrS = mini_y[1]\n",
    "\n",
    "        #get probabilities and predictions\n",
    "        mini_BrS_probas = mini_pred_probas[:,1]\n",
    "        mini_BrS_predictions = mini_pred_probas.argmax(axis = -1)\n",
    "        \n",
    "        \n",
    "        if mini_BrS == 0:\n",
    "            if mini_BrS_predictions == 0:\n",
    "                TN = TN +1\n",
    "                file_id_conf_mat[\"TN\"].append(s)\n",
    "                \n",
    "                \n",
    "            if mini_BrS_predictions == 1:\n",
    "                FP = FP +1\n",
    "                file_id_conf_mat[\"FP\"].append(s)\n",
    "        \n",
    "        if mini_BrS == 1:\n",
    "            if mini_BrS_predictions == 1:\n",
    "                TP = TP +1\n",
    "                file_id_conf_mat[\"TP\"].append(s)\n",
    "                \n",
    "            if mini_BrS_predictions == 0:\n",
    "                FN = FN +1\n",
    "                file_id_conf_mat[\"FN\"].append(s)\n",
    "                \n",
    "    p_id_reprod[p] = [labels[s], TN, FP, TP, FN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ff384",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = p_id_reprod\n",
    "reprod = pd.DataFrame.from_dict(data, orient='index',\n",
    "                       columns=['label', 'TN', 'FP', 'TP', 'FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprod[\"number_of_samples\"] = reprod[\"TN\"] + reprod[\"TP\"] + reprod[\"FN\"] + reprod[\"FP\"]\n",
    "reprod[\"fraction_correct_labels\"] = (reprod[\"TN\"] + reprod[\"TP\"]) / reprod[\"number_of_samples\"]\n",
    "reprod[\"all_samples_correctly_predicted\"] = np.where(reprod[\"fraction_correct_labels\"]== 1, True, False)\n",
    "reprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be47b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of different negative test patients: \", reprod[reprod[\"label\"]==0].shape[0], \" number of negative samples: \",sum(reprod[reprod[\"label\"]==0][\"number_of_samples\"])) \n",
    "print(\"number negative samples per patient: \", sum(reprod[reprod[\"label\"]==0][\"number_of_samples\"])/reprod[reprod[\"label\"]==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a907bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of different positive test patients: \", reprod[reprod[\"label\"]==1].shape[0], \" number of positive samples: \",sum(reprod[reprod[\"label\"]==1][\"number_of_samples\"]))\n",
    "print(\"number positive samples per patient: \", sum(reprod[reprod[\"label\"]==1][\"number_of_samples\"])/reprod[reprod[\"label\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abf694",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of samples for positive patients\")\n",
    "sum(reprod[reprod[\"label\"]==1][\"number_of_samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b207c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of samples for negative patients\")\n",
    "sum(reprod[reprod[\"label\"]==0][\"number_of_samples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2b2c6",
   "metadata": {},
   "source": [
    "## Drop patients with less than two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b1552",
   "metadata": {},
   "outputs": [],
   "source": [
    "reprod = reprod[reprod[\"number_of_samples\"]>=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of different negative test patients: \", reprod[reprod[\"label\"]==0].shape[0], \" number of negative samples: \",sum(reprod[reprod[\"label\"]==0][\"number_of_samples\"])) \n",
    "print(\"number negative samples per patient: \", sum(reprod[reprod[\"label\"]==0][\"number_of_samples\"])/reprod[reprod[\"label\"]==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bca6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of different positive test patients: \", reprod[reprod[\"label\"]==1].shape[0], \" number of positive samples: \",sum(reprod[reprod[\"label\"]==1][\"number_of_samples\"]))\n",
    "print(\"number positive samples per patient: \", sum(reprod[reprod[\"label\"]==1][\"number_of_samples\"])/reprod[reprod[\"label\"]==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of samples for positive patients\")\n",
    "sum(reprod[reprod[\"label\"]==1][\"number_of_samples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of samples for negative patients\")\n",
    "sum(reprod[reprod[\"label\"]==0][\"number_of_samples\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0452d",
   "metadata": {},
   "source": [
    "## Fraction of correct labels : within patient agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"General fraction of correct labels\")\n",
    "print(np.mean(reprod[\"fraction_correct_labels\"]), np.median(reprod[\"fraction_correct_labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eff8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10, 10))\n",
    "ax = fig.add_axes([0, 0, 1, 1]) \n",
    "bp = ax.boxplot(reprod[\"fraction_correct_labels\"]) \n",
    "ax.set_xticklabels(['All groups'])\n",
    "plt.title(\"Distribution of fraction of correct labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = reprod[reprod[\"label\"]==0][\"fraction_correct_labels\"]\n",
    "data_2 = reprod[reprod[\"label\"]==1][\"fraction_correct_labels\"]\n",
    "df = [data_1, data_2]\n",
    "fig = plt.figure(figsize =(10, 10)) \n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.set_xticklabels(['No BrP', 'BrP'])\n",
    "bp = ax.boxplot(df)\n",
    "plt.title(\"Distribution of fraction of correct labels for positive and negative samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719bb8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"mean ratio of correct predictions per patient, positives: \", np.mean(reprod[reprod[\"label\"]==1][\"fraction_correct_labels\"]),\n",
    "     \", negatives: \", np.mean(reprod[reprod[\"label\"]==0][\"fraction_correct_labels\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a14f0",
   "metadata": {},
   "source": [
    "## 100%-within patient agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of samples per patient for patients for which at least one prediction was wrong\")\n",
    "print(np.mean(reprod[reprod[\"all_samples_correctly_predicted\"]==False][\"number_of_samples\"]), \n",
    "      np.median(reprod[reprod[\"all_samples_correctly_predicted\"]==False][\"number_of_samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of samples per patient for patients for which all predictions were right\")\n",
    "print(np.mean(reprod[reprod[\"all_samples_correctly_predicted\"]==True][\"number_of_samples\"]), \n",
    "      np.median(reprod[reprod[\"all_samples_correctly_predicted\"]==True][\"number_of_samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c400ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots\n",
    "data_1 = reprod[reprod[\"all_samples_correctly_predicted\"]==False][\"number_of_samples\"]\n",
    "data_2 = reprod[reprod[\"all_samples_correctly_predicted\"]==True][\"number_of_samples\"]\n",
    "df = [data_1, data_2]\n",
    "fig = plt.figure(figsize =(10, 7)) \n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.set_xticklabels(['>1 incorrect prediction', 'All correct'])\n",
    "bp = ax.boxplot(df)\n",
    "plt.title(\"Distribution of number of samples with respect to whether all samples were correctly classified for each patient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = reprod[reprod[\"all_samples_correctly_predicted\"]==True] #patients for which 100% within patient agreement was obtained\n",
    "incorrect = reprod[reprod[\"all_samples_correctly_predicted\"]==False] #patients for which less than 100% within patient agreement was obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"propotion of samples that reached 100% within patient agreement \", correct.shape[0]/(correct.shape[0]+incorrect.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of positive samples per patient for whom all ecgs were correctly classified\")\n",
    "print(np.mean(correct[correct[\"label\"]==1][\"number_of_samples\"]), \n",
    "      np.median(correct[correct[\"label\"]==1][\"number_of_samples\"]))\n",
    "\n",
    "print(\"fraction of positive samples for which all sample predictions agreed \",correct[correct[\"label\"]==1].shape[0] / (correct[correct[\"label\"]==1].shape[0] + incorrect[incorrect[\"label\"]==1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of negative samples per patient for whom all ecgs were correctly classified\")\n",
    "print(np.mean(correct[correct[\"label\"]==0][\"number_of_samples\"]), \n",
    "      np.median(correct[correct[\"label\"]==0][\"number_of_samples\"]))\n",
    "print(\"fraction of negative samples for which all sample predictions agreed \",correct[correct[\"label\"]==0].shape[0] / (correct[correct[\"label\"]==0].shape[0] + incorrect[incorrect[\"label\"]==0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c048f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of negative samples per patient for whom all at least one ecg was incorrectly classified\")\n",
    "print(np.mean(incorrect[incorrect[\"label\"]==0][\"number_of_samples\"]), \n",
    "      np.median(incorrect[incorrect[\"label\"]==0][\"number_of_samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dcaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of positive samples per patient for whom all at least one ecg was incorrectly classified\")\n",
    "print(np.mean(incorrect[incorrect[\"label\"]==1][\"number_of_samples\"]), \n",
    "      np.median(incorrect[incorrect[\"label\"]==1][\"number_of_samples\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e40221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots\n",
    "data_1 = correct[correct[\"label\"]==1][\"number_of_samples\"]\n",
    "data_2 = correct[correct[\"label\"]==0][\"number_of_samples\"]\n",
    "data_3 = incorrect[incorrect[\"label\"]==1][\"number_of_samples\"]\n",
    "data_4 = incorrect[incorrect[\"label\"]==0][\"number_of_samples\"]\n",
    "\n",
    "df = [data_1, data_2, data_3, data_4]\n",
    "fig = plt.figure(figsize=(10,8)) \n",
    "ax = fig.add_axes([0.1, 0.1, 0.75, 0.75])\n",
    "ax.set_xticklabels([\"All correct and BrP\", \"All correct and no BrP\", \">1 incorrect and BrP\", \">1 incorrect and no BrP\"])\n",
    "ax.set_ylabel(\"Number of samples per patient \")\n",
    "ax.boxplot(df)\n",
    "#plt.title(\"Distribution of number of samples with respect to whether all samples were correctly classified for one patient per true label\")\n",
    "fig.savefig(plot_path + \"BoxPlot_all_correct_at_least_one_wrong_per_class.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0839c0b",
   "metadata": {},
   "source": [
    "## New AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(figsize = (10,10))\n",
    "colors = {0:\"green\", 1: \"red\"}\n",
    "labels = {0: \"no BrP\", 1: \"BrP\"}\n",
    "grouped = reprod.groupby(\"label\")\n",
    "for key, group in grouped:\n",
    "    group.plot(ax = ax, kind =\"scatter\", x = \"number_of_samples\", y= \"fraction_correct_labels\", label = labels[key], color = colors[key], s=50)\n",
    "ax.set(xlabel = \"Samples available per patient\", ylabel = \"Fraction of correctly predicted labels\")\n",
    "plt.rc(\"axes\", labelsize=25)\n",
    "plt.rc(\"legend\", fontsize=20)\n",
    "plt.rc(\"xtick\", labelsize = 20)\n",
    "plt.rc(\"ytick\", labelsize = 20)\n",
    "plt.savefig(plot_path + \"scatter_fraction_correct_per_n_samples.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_avg_fraction_correct_labels = reprod.groupby(\"number_of_samples\", as_index=False)[\"fraction_correct_labels\"].mean()\n",
    "plt.scatter(gp_avg_fraction_correct_labels[\"number_of_samples\"], gp_avg_fraction_correct_labels[\"fraction_correct_labels\"])\n",
    "plt.title(\"Scatter plot of average fraction of correctly predicted labels grouped by the number of samples available per patient\")\n",
    "plt.xlabel(\"Samples available per patient\")\n",
    "plt.ylabel(\"Average fraction of correctly predicted labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b6d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = reprod[reprod[\"label\"]==1]\n",
    "plt.scatter(a[\"number_of_samples\"], a[\"fraction_correct_labels\"])\n",
    "plt.title(\"Scatter plot of fraction of correctly predicted labels with respect to the number of samples available per patient\")\n",
    "plt.xlabel(\"Samples available per patient\")\n",
    "plt.ylabel(\"Fraction of correctly predicted labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a86114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_avg_fraction_correct_labels = a.groupby(\"number_of_samples\", as_index=False)[\"fraction_correct_labels\"].mean()\n",
    "plt.scatter(gp_avg_fraction_correct_labels[\"number_of_samples\"], gp_avg_fraction_correct_labels[\"fraction_correct_labels\"])\n",
    "plt.title(\"Scatter plot of average fraction of correctly predicted labels grouped by the number of samples available per patient\")\n",
    "plt.xlabel(\"Samples available per patient\")\n",
    "plt.ylabel(\"Average fraction of correctly predicted labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = reprod[reprod[\"label\"]==0]\n",
    "plt.scatter(b[\"number_of_samples\"], b[\"fraction_correct_labels\"])\n",
    "plt.title(\"Scatter plot of fraction of correctly predicted labels with respect to the number of samples available per patient\")\n",
    "plt.xlabel(\"Samples available per patient\")\n",
    "plt.ylabel(\"Fraction of correctly predicted labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9aac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_avg_fraction_correct_labels = b.groupby(\"number_of_samples\", as_index=False)[\"fraction_correct_labels\"].mean()\n",
    "plt.scatter(gp_avg_fraction_correct_labels[\"number_of_samples\"], gp_avg_fraction_correct_labels[\"fraction_correct_labels\"])\n",
    "plt.title(\"Scatter plot of average fraction of correctly predicted labels grouped by the number of samples available per patient\")\n",
    "plt.xlabel(\"Samples available per patient\")\n",
    "plt.ylabel(\"Average fraction of correctly predicted labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defeaf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new probabilities\n",
    "#if positive label probability of BrP is fraction of correct\n",
    "#if negative label, probability of BrP is 1- fraction of correct\n",
    "reprod[\"new_probas\"] = \"\"\n",
    "reprod.loc[reprod[\"label\"]==1, \"new_probas\"] = reprod[\"fraction_correct_labels\"]\n",
    "reprod.loc[reprod[\"label\"]==0, \"new_probas\"] = 1 - reprod[\"fraction_correct_labels\"]\n",
    "reprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df532e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict based on fraction of correctly predicted\n",
    "original_labels = reprod[\"label\"]\n",
    "new_probas = reprod[\"new_probas\"]\n",
    "#new_predictions = reprod[\"new_probas\"].astype(\"float\").round(0)\n",
    "new_predictions = [1 if elem >= 0.5 else 0 for elem in new_probas]\n",
    "metrics =[]\n",
    "performance_metrics(original_labels,new_predictions, new_probas, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f79e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(original_labels, new_probas)\n",
    "auc_coef = round(auc(fpr, tpr),3)\n",
    "f, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(fpr, tpr, marker=\".\", label = model_type[\"type\"] + \" - AUC: \" + str(auc_coef))\n",
    "ax.plot([0,1], [0,1], transform = ax.transAxes, linestyle=\"--\", label=\"Random Classifier\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"ROC\")\n",
    "ax.legend()\n",
    "plt.savefig(plot_path + \"ROC_PP.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb78884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision Recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(original_labels, new_probas)\n",
    "auprc = round(auc(recall, precision),3)\n",
    "f, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(recall, precision, marker=\".\", label = model_type[\"type\"] + \" - AUPRC: \" + str(auprc))\n",
    "ax.set_xlabel(\"Recall (Positive label: Brugada)\")\n",
    "ax.set_ylabel(\"Precision (Positive label: Brugada)\")\n",
    "ax.set_title(\"AUPRC\")\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.legend()\n",
    "plt.savefig(plot_path + \"AUPC_PP.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_together(original_labels.astype(float), new_probas.astype(float), per_patient = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074313f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution(original_labels, {\"Predicted probabilities\": np.array(new_probas)}, per_patient = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68c3c6",
   "metadata": {},
   "source": [
    "# Filters data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d70d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_filters[\"combination\"] = list(zip(neg_filters.high_pass, neg_filters.low_pass, neg_filters.ac))\n",
    "pos_filters[\"combination\"] = list(zip(pos_filters.high_pass, pos_filters.low_pass, pos_filters.ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_filters = neg_filters.set_index('id')\n",
    "pos_filters = pos_filters.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f08e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_filters[\"classification_result\"]=\"\"\n",
    "pos_filters[\"classification_result\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c93572",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in file_id_conf_mat:\n",
    "    for ecg_id in file_id_conf_mat[key]:\n",
    "                \n",
    "        if ecg_id in neg_filters.index:\n",
    "            neg_filters.loc[ecg_id, \"classification_result\"] = key\n",
    "        \n",
    "        if ecg_id in pos_filters.index:\n",
    "            pos_filters.loc[ecg_id, \"classification_result\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef78019",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_filters['binary_result'] = np.where(neg_filters[\"classification_result\"]== \"TN\", 1, 0)\n",
    "pos_filters['binary_result'] = np.where(pos_filters[\"classification_result\"]== \"TP\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cfe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_n_per_filter = neg_filters.groupby([\"combination\"]).size().reset_index(name=\"n_per_filter\")\n",
    "pos_n_per_filter = pos_filters.groupby([\"combination\"]).size().reset_index(name=\"n_per_filter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e822412",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_correct_per_filter = pd.DataFrame(neg_filters.groupby(['combination'])['binary_result'].sum())\n",
    "pos_correct_per_filter = pd.DataFrame(pos_filters.groupby(['combination'])['binary_result'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fe18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_correct_per_filter = neg_correct_per_filter.rename(columns={\"binary_result\": \"n_correct\"})\n",
    "pos_correct_per_filter = pos_correct_per_filter.rename(columns={\"binary_result\": \"n_correct\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe631e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_n_per_filter = neg_n_per_filter.set_index('combination').join(neg_correct_per_filter)\n",
    "pos_n_per_filter = pos_n_per_filter.set_index('combination').join(pos_correct_per_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a89841",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_n_per_filter[\"n_incorrect\"] = neg_n_per_filter[\"n_per_filter\"]  - neg_n_per_filter[\"n_correct\"]\n",
    "pos_n_per_filter[\"n_incorrect\"] = pos_n_per_filter[\"n_per_filter\"]  - pos_n_per_filter[\"n_correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96649e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_n_per_filter[\"correct_over_n\"] = neg_n_per_filter[\"n_correct\"] / neg_n_per_filter[\"n_per_filter\"]\n",
    "pos_n_per_filter[\"correct_over_n\"] = pos_n_per_filter[\"n_correct\"] / pos_n_per_filter[\"n_per_filter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_n_per_filter = p_filter_combo[[\"combination\", \"percentage_by_class\"]].set_index('combination').join(pos_n_per_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9517cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_n_per_filter = n_filter_combo[[\"combination\", \"percentage_by_class\"]].set_index('combination').join(neg_n_per_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dae910",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_n_per_filter.sort_values(by=['correct_over_n'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58edba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_n_per_filter.sort_values(by=['correct_over_n'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cf998",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter_combo = n_filter_combo.set_index(\"combination\")\n",
    "n_filter_combo = n_filter_combo.reindex(index = p_filter_combo[\"combination\"])\n",
    "n_filter_combo = n_filter_combo.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_index = 1\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12, 10))\n",
    "\n",
    "ind = np.arange(pos_n_per_filter.shape[0])\n",
    "width = 0.35\n",
    "\n",
    "rects_neg = ax1.bar(ind - width/2, neg_n_per_filter[\"percentage_by_class\"], width, label = \"No BrP\")\n",
    "rects_pos = ax1.bar(ind + width/2, pos_n_per_filter[\"percentage_by_class\"], width, label = \"BrP\")\n",
    "ax1.set_ylabel(\"Percentage of samples\")\n",
    "ax1.set_xlabel(\"Filter combinations\")\n",
    "#ax1.set_title(\"Percentage of samples per filter combination per class\")\n",
    "ax1.set_xticks(ind)\n",
    "y_labels = list(neg_n_per_filter.index)\n",
    "ax1.set_xticklabels(y_labels)\n",
    "ax1.legend()\n",
    "\n",
    "rects_neg = ax2.bar(ind - width/2, neg_n_per_filter[\"correct_over_n\"], width, label = \"No BrP\")\n",
    "rects_pos = ax2.bar(ind + width/2, pos_n_per_filter[\"correct_over_n\"], width, label = \"BrP\")\n",
    "ax2.set_ylabel(\"Ratio of correctly predicted samples per filter combination\")\n",
    "#ax2.set_title(\"Ratio of correctly predicted samples per filter combination per class\")\n",
    "ax2.set_xticks(ind)\n",
    "y_labels = list(neg_n_per_filter.index)\n",
    "ax2.set_xticklabels(y_labels)\n",
    "ax2.set_xlabel(\"Filter combinations\")\n",
    "ax2.legend()\n",
    "\n",
    "plt.savefig(plot_path + \"performance_per_filter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e312e",
   "metadata": {},
   "source": [
    "## Performance metrics per filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = neg_filters[[\"combination\", \"classification_result\"]].append(pos_filters[[\"combination\", \"classification_result\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e33dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(data[\"classification_result\"])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['FN', 'FP', 'TN', 'TP']]=onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559518f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef67431",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_performance = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8078baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_performance[\"FN\"] = data.groupby('combination')['FN'].sum()\n",
    "filter_performance[\"FP\"] = data.groupby('combination')['FP'].sum()\n",
    "filter_performance[\"TN\"] = data.groupby('combination')['TN'].sum()\n",
    "filter_performance[\"TP\"] = data.groupby('combination')['TP'].sum()\n",
    "filter_performance[\"PPV/precision\"] = filter_performance[\"TP\"]/(filter_performance[\"TP\"]+filter_performance[\"FP\"])\n",
    "filter_performance[\"TNR/specificity\"] = filter_performance[\"TN\"]/(filter_performance[\"TN\"]+filter_performance[\"FP\"])\n",
    "filter_performance[\"FNR/specificity\"] = filter_performance[\"FN\"]/(filter_performance[\"FN\"]+filter_performance[\"TP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0da88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c939e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export predictions to csv\n",
    "labels_and_predictions_p_sample = pd.DataFrame(list(zip(BrS, BrS_probas)), columns = [\"label_per_sample\", \"prediction_per_sample\"])\n",
    "labels_and_predictions_p_patient = pd.DataFrame(list(zip(original_labels, new_probas)), columns = [\"label_per_sample\", \"prediction_per_sample\"])\n",
    "labels_and_predictions_p_sample.to_csv(\"ecg_predictions_per_sample.csv\", index=False)\n",
    "labels_and_predictions_p_patient.to_csv(\"ecg_predictions_per_patient.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
